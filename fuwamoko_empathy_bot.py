# ğŸ”½ ğŸ“¦ Pythonã®æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from datetime import datetime, timezone
import os
import time
import random
import requests
from io import BytesIO
import filelock
import re
import logging
import cv2
import numpy as np
from urllib.parse import quote, unquote
from PIL import Image, UnidentifiedImageError, ImageFile
from copy import deepcopy
import json

# ğŸ”½ ğŸŒ± å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer
from collections import Counter
import torch

# ğŸ”½ ğŸ“¡ atprotoé–¢é€£
from atproto import Client, models

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(filename='debug.log', level=logging.DEBUG, format='%(asctime)s %(message)s', encoding='utf-8')
logging.getLogger().addHandler(logging.StreamHandler())

# PILã®ã‚¨ãƒ©ãƒ¼æŠ‘åˆ¶
ImageFile.LOAD_TRUNCATED_IMAGES = True

# ğŸ”½ ğŸ§  Transformersç”¨è¨­å®š
MODEL_NAME = "cyberagent/open-calm-small"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=".cache")
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    cache_dir=".cache",
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto"
)
tokenizer.pad_token = tokenizer.eos_token

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
HANDLE = os.environ.get("HANDLE")
APP_PASSWORD = os.environ.get("APP_PASSWORD")
SESSION_FILE = "session_string.txt"
FUWAMOKO_FILE = "fuwamoko_empathy_uris.txt"
FUWAMOKO_LOCK = "fuwamoko_empathy_uris.lock"

# ğŸ”½ ãƒ†ãƒ³ãƒ—ãƒ¬ä¿è­·ï¼ˆãƒãƒ£ãƒƒãƒ”ãƒ¼æ†²ç« ï¼‰
LOCK_TEMPLATES = True
ORIGINAL_TEMPLATES = {
    "NORMAL_TEMPLATES_JP": [
        "ã†ã‚“ã†ã‚“ã€ã‹ã‚ã„ã„ã­ï¼ç™’ã•ã‚ŒãŸã‚ˆğŸ¾ğŸ’–",
        "ã‚ˆã‹ã£ãŸã­ã€œï¼ãµã‚ãµã‚ã ã­ğŸŒ¸ğŸ§¸",
        "ãˆã¸ã£ã€ãƒ¢ãƒ•ãƒ¢ãƒ•ã§ç™’ã—MAXï¼ğŸ’",
        "ã†ã‚ã£ï¼å¯æ„›ã™ãã‚‹ã‚ˆğŸ¾ğŸŒ·",
        "ãµã‚ãµã‚ã ã­ã€å…ƒæ°—å‡ºãŸï¼ğŸ’«ğŸ§¸"
    ],
    "SHONBORI_TEMPLATES_JP": [
        "ãã£ã‹â€¦ãã‚…ãƒ¼ã£ã¦ã—ã¦ã‚ã’ã‚‹ã­ğŸ¾ğŸ’•",
        "å…ƒæ°—å‡ºã—ã¦ã­ã€ãµã‚ã‚‚ã“ãƒ‘ãƒ¯ãƒ¼é€ã‚‹ã‚ˆï¼ğŸ§¸âœ¨",
        "ã¤ã‚‰ã„ã¨ãã“ãã€ãµã‚ãµã‚ã«åŒ…ã¾ã‚Œã¦â€¦ğŸ°â˜ï¸",
        "ç„¡ç†ã—ãªã„ã§ã­ã€ãã£ã¨å¯„ã‚Šæ·»ã†ã‚ˆğŸ§¸ğŸŒ¸"
    ],
    "MOGUMOGU_TEMPLATES_JP": [
        "ã†ãƒ¼ã‚“â€¦ã“ã‚Œã¯ç™’ã—ã‚ˆã‚Šç¾å‘³ã—ãã†ï¼ŸğŸ¾ğŸ’­",
        "ã‚‚ãã‚‚ãã—ã¦ã‚‹ã‘ã©â€¦ãµã‚ã‚‚ã“ã˜ã‚ƒãªã„ã‹ãªï¼ŸğŸ¤”",
        "ã¿ã‚Šã‚“ã¦ã‚ƒã€ãŠè…¹ç©ºã„ã¦ãã¡ã‚ƒã£ãŸâ€¦é£Ÿãƒ¬ãƒï¼ŸğŸ½ï¸ğŸ’¬"
    ],
    "NORMAL_TEMPLATES_EN": [
        "Wow, so cute! Feels good~ ğŸ¾ğŸ’–",
        "Nice! So fluffy~ ğŸŒ¸ğŸ§¸",
        "Great! Healing vibes! ğŸ’",
        "Amazing! Thanks for the fluff! ğŸ¾ğŸŒ·"
    ],
    "MOGUMOGU_TEMPLATES_EN": [
        "Hmmm... looks tasty, but maybe not so fluffy? ğŸ¾ğŸ’­",
        "So yummy-looking... but is this a snack or a friend? ğŸ¤”ğŸ½ï¸",
        "This might be food, not a fluffy cutie... ğŸ½ï¸ğŸ’­",
        "Adorable! But maybe not a fluffy buddy? ğŸ‘ğŸ’¬"
    ],
    "COSMETICS_TEMPLATES_JP": {
        "ãƒªãƒƒãƒ—": ["ã“ã®ãƒªãƒƒãƒ—å¯æ„›ã„ã€œğŸ’„ğŸ’–", "è‰²å‘³ãŒç´ æ•µã™ãã¦ã†ã£ã¨ã‚Šã—ã¡ã‚ƒã†ğŸ’‹"],
        "é¦™æ°´": ["ã“ã®é¦™ã‚Šã€çµ¶å¯¾ãµã‚ã‚‚ã“ã ã‚ˆã­ğŸŒ¸", "ã„ã„åŒ‚ã„ã€œï¼ğŸ’•"],
        "ãƒã‚¤ãƒ«": ["ãã®ãƒã‚¤ãƒ«ã€ã‚­ãƒ©ã‚­ãƒ©ã—ã¦ã¦æœ€é«˜ğŸ’…âœ¨", "ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼ã§ç´ æ•µã€œğŸ’–"]
    },
    "COSMETICS_TEMPLATES_EN": {
        "lip": ["That lipstick is so cute~ ğŸ’„ğŸ’–", "The color is dreamy, Iâ€™m in love ğŸ’‹"],
        "perfume": ["I bet that perfume smells fluffy and sweet ğŸŒ¸", "I can almost smell it~ so lovely! ğŸŒ¼"],
        "nail": ["That nail art is sparkly and perfect ğŸ’…âœ¨", "Fluffy colors make it so pretty ğŸ’–"]
    },
    "CHARACTER_TEMPLATES_JP": {
        "ã‚¢ãƒ‹ãƒ¡": ["ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ãŒãƒ¢ãƒ•ãƒ¢ãƒ•ï¼ğŸ’•", "ã¾ã‚‹ã§å¤¢ã®ä¸–ç•Œã®ä½äººğŸŒŸ"],
        "ä¸€æ¬¡å‰µä½œ": ["ã‚ªãƒªã‚­ãƒ£ãƒ©å°Šã„â€¦ğŸ¥ºâœ¨", "ã“ã®å­ã ã‘ã®ä¸–ç•Œè¦³ãŒã‚ã‚‹ã­ğŸ’–"],
        "fanart": ["ã“ã®è§£é‡ˆã€å¤©æ‰ã™ãã‚‹â€¦ï¼ğŸ™Œ", "åŸä½œæ„›ãŒä¼ã‚ã£ã¦ãã‚‹ã‚ˆâœ¨"]
    },
    "CHARACTER_TEMPLATES_EN": {
        "anime": ["Such a fluffy anime character! ğŸ’•", "They look like someone from a dream world~ ğŸŒŸ"],
        "oc": ["Your OC is precious... ğŸ¥ºâœ¨", "They have such a unique vibe, I love it! ğŸ’–"],
        "fanart": ["Amazing interpretation! You're a genius ğŸ™Œ", "I can feel your love for the original work âœ¨"]
    }
}

# ğŸ”½ ã‚°ãƒ­ãƒ¼ãƒãƒ«è¾æ›¸åˆæœŸåŒ–
try:
    _ = globals()["HIGH_RISK_WORDS"]
except KeyError:
    logging.error("âš ï¸ HIGH_RISK_WORDSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["HIGH_RISK_WORDS"] = [
        "ã‚‚ã¡ã‚‚ã¡", "ã·ã«ã·ã«", "ã·ã‚ˆã·ã‚ˆ", "ã‚„ã‚ã‚‰ã‹ã„", "ã‚€ã«ã‚…ã‚€ã«ã‚…", "ã‚¨ãƒ­", "ãˆã£ã¡",
        "nude", "nsfw", "naked", "lewd", "18+", "sex", "uncensored"
    ]

try:
    _ = globals()["EMOTION_TAGS"]
except KeyError:
    logging.error("âš ï¸ EMOTION_TAGSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["EMOTION_TAGS"] = {
        "fuwamoko": ["ãµã‚ãµã‚", "ã‚‚ã“ã‚‚ã“", "ã‚‚ãµã‚‚ãµ", "fluffy", "fluff", "fluffball", "ãµã‚ã‚‚ã“",
                     "ã½ã‚ˆã½ã‚ˆ", "ã‚„ã‚ã‚„ã‚", "ãã‚…ã‚‹ãã‚…ã‚‹", "ã½ãµã½ãµ", "ãµã‚ã‚‚ãµ", "ã½ã“ã½ã“"],
        "neutral": ["ã‹ã‚ã„ã„", "cute", "adorable", "æ„›ã—ã„"],
        "shonbori": ["ã—ã‚‡ã‚“ã¼ã‚Š", "ã¤ã‚‰ã„", "ã‹ãªã—ã„", "ã•ã³ã—ã„", "ç–²ã‚ŒãŸ", "ã¸ã“ã‚“ã ", "æ³£ããã†"],
        "food": ["è‚‰", "ã”é£¯", "é£¯", "ãƒ©ãƒ³ãƒ", "ãƒ‡ã‚£ãƒŠãƒ¼", "ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°", "ã”ã¯ã‚“",
                 "ãŠã„ã—ã„", "ã†ã¾ã„", "ç¾å‘³", "ã„ãŸã ãã¾ã™", "ãŸã¹ãŸ", "é£Ÿ", "ã”ã¡ãã†", "ã”é¦³èµ°",
                 "ã¾ãã‚", "åˆºèº«", "ãƒãƒ¼ã‚º", "ã‚¹ãƒŠãƒƒã‚¯", "yummy", "delicious", "ã‚¹ãƒ¼ãƒ—",
                 "å‘³å™Œæ±", "ã‚«ãƒ«ãƒœãƒŠãƒ¼ãƒ©", "é‹", "éºº", "ãƒ‘ãƒ³", "ãƒˆãƒ¼ã‚¹ãƒˆ",
                 "ã‚«ãƒ•ã‚§", "ã‚¸ãƒ¥ãƒ¼ã‚¹", "ãƒŸãƒ«ã‚¯", "ãƒ‰ãƒªãƒ³ã‚¯", "ãŠã‚„ã¤", "é£Ÿäº‹", "æœé£Ÿ", "å¤•é£Ÿ", "æ˜¼é£Ÿ",
                 "é…’", "ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«", "ãƒ“ãƒ¼ãƒ«", "ãƒ¯ã‚¤ãƒ³", "é…ãƒã‚¤", "ã‚«ã‚¯ãƒ†ãƒ«", "ãƒã‚¤ãƒœãƒ¼ãƒ«", "æ¢…é…’"],
        "safe_cosmetics": ["ã‚³ã‚¹ãƒ¡", "ãƒ¡ã‚¤ã‚¯", "ãƒªãƒƒãƒ—", "é¦™æ°´", "ã‚¹ã‚­ãƒ³ã‚±ã‚¢", "ãƒã‚¤ãƒ«", "çˆª", "ãƒãƒ‹ã‚­ãƒ¥ã‚¢",
                          "cosmetics", "makeup", "perfume", "nail", "lip", "lipstick", "lip gloss", "lip balm",
                          "fragrance", "scent", "nail art", "manicure", "nails"]
    }

try:
    _ = globals()["SAFE_CHARACTER"]
except KeyError:
    logging.error("âš ï¸ SAFE_CHARACTERæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["SAFE_CHARACTER"] = {
        "ã‚¢ãƒ‹ãƒ¡": ["ã‚¢ãƒ‹ãƒ¡", "æ¼«ç”»", "ãƒãƒ³ã‚¬", "ã‚¤ãƒ©ã‚¹ãƒˆ", "anime", "illustration", "drawing", "anime art", "manga", "fanart"],
        "ä¸€æ¬¡å‰µä½œ": ["ä¸€æ¬¡å‰µä½œ", "ã‚ªãƒªã‚­ãƒ£ãƒ©", "ã‚ªãƒªã‚¸ãƒŠãƒ«", "å‰µä½œ", "oc", "original character", "my oc"],
        "fanart": ["ãƒ•ã‚¡ãƒ³ã‚¢ãƒ¼ãƒˆ", "FA", "fanart", "fan art", "fandom art"]
    }

try:
    _ = globals()["GENERAL_TAGS"]
except KeyError:
    logging.error("âš ï¸ GENERAL_TAGSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["GENERAL_TAGS"] = ["ã‚­ãƒ£ãƒ©", "æ¨ã—", "art", "drawing"]

# ãƒ†ãƒ³ãƒ—ãƒ¬ç›£æŸ»ãƒ­ã‚°
TEMPLATE_AUDIT_LOG = "template_audit_log.txt"

def audit_templates_changes(old, new):
    try:
        if old != new:
            with open(TEMPLATE_AUDIT_LOG, "a", encoding="utf-8") as f:
                f.write(json.dumps({
                    "timestamp": datetime.now().isoformat(),
                    "before": old,
                    "after": new
                }, ensure_ascii=False, indent=2) + "\n")
            logging.warning("âš ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬å¤‰æ›´æ¤œå‡º")
    except Exception as e:
        logging.error(f"âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ç›£æŸ»ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def check_template_integrity(templates):
    if not LOCK_TEMPLATES:
        logging.warning("âš ï¸ LOCK_TEMPLATESç„¡åŠ¹ã€æ”¹å¤‰ãƒªã‚¹ã‚¯")
        return False
    for key in ORIGINAL_TEMPLATES:
        if templates.get(key) != ORIGINAL_TEMPLATES[key]:
            logging.error(f"âš ï¸ {key} æ”¹å¤‰æ¤œå‡ºã€å¾©å…ƒæ¨å¥¨")
            return False
    return True

def auto_revert_templates(templates):
    if LOCK_TEMPLATES:
        for key in ORIGINAL_TEMPLATES:
            templates[key] = deepcopy(ORIGINAL_TEMPLATES[key])
        logging.info("âœ… ãƒ†ãƒ³ãƒ—ãƒ¬å¾©å…ƒå®Œäº†")
        return templates
    return templates

def is_fluffy_color(r, g, b):
    logging.debug(f"ğŸ§ª è‰²åˆ¤å®š: RGB=({r}, {g}, {b})")

    # ç™½ç³»ï¼ˆå°‘ã—æš—ã‚ã§ã‚‚è¨±å®¹ï¼‰
    if r > 180 and g > 180 and b > 180:
        logging.debug("ç™½ç³»æ¤œå‡ºï¼ˆå„ªã—ã‚ï¼‰")
        return True

    # ãƒ”ãƒ³ã‚¯ç³»ï¼ˆæ˜ã‚‹ã•å„ªå…ˆï¼‰
    if r > 200 and g < 150 and b > 170:
        logging.debug("ãƒ”ãƒ³ã‚¯ç³»æ¤œå‡ºï¼ˆã‚†ã‚‹ã‚ï¼‰")
        return True

    # ã‚¯ãƒªãƒ¼ãƒ è‰²ï¼ˆç™½é»„ç³»ï¼‰
    if r > 220 and g > 210 and b > 170:
        logging.debug("ã‚¯ãƒªãƒ¼ãƒ è‰²æ¤œå‡ºï¼ˆåºƒã‚ï¼‰")
        return True

    # ãƒ‘ã‚¹ãƒ†ãƒ«ãƒ‘ãƒ¼ãƒ—ãƒ«ï¼ˆrã¨bã®å·®ã‚’ã‚†ã‚‹ãï¼‰
    if r > 190 and b > 190 and abs(r - b) < 60 and g > 160:
        logging.debug("ãƒ‘ã‚¹ãƒ†ãƒ«ãƒ‘ãƒ¼ãƒ—ãƒ«æ¤œå‡ºï¼ˆã‚†ã‚‹ã‚ï¼‰")
        return True

    # ç™½ç°ãƒ”ãƒ³ã‚¯ç³»ï¼ˆæ¡ƒèŠ±ã¡ã‚ƒã‚“å¯¾å¿œï¼‰
    if r > 200 and g > 180 and b > 200:
        logging.debug("ãµã‚ã‚‚ã“ç™½ç°ãƒ”ãƒ³ã‚¯æ¤œå‡ºï¼ˆæ¡ƒèŠ±å¯¾å¿œï¼‰")
        return True

    # ç™½ç°ç³»ï¼ˆã»ã‚“ã®ã‚Šã‚°ãƒ¬ãƒ¼ã‚‚OKï¼‰
    if 200 <= r <= 255 and 200 <= g <= 240 and 200 <= b <= 255 and abs(r - g) < 30 and abs(r - b) < 30:
        logging.debug("ç™½ç°ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼ï¼ˆæŸ”ã‚‰ã‹ç³»ï¼‰")
        return True

    hsv = cv2.cvtColor(np.array([[[r, g, b]]], dtype=np.uint8), cv2.COLOR_RGB2HSV)[0][0]
    h, s, v = hsv
    logging.debug(f"HSV=({h}, {s}, {v})")

    if 200 <= h <= 300 and s < 80 and v > 180:
        logging.debug("ãƒ‘ã‚¹ãƒ†ãƒ«ç³»ç´«ï½ãƒ”ãƒ³ã‚¯æ¤œå‡º")
        return True

    if 190 <= h <= 260 and s < 100 and v > 140:
        logging.debug("å¤œç©ºãƒ‘ã‚¹ãƒ†ãƒ«ç´«æ¤œå‡ºï¼ˆåºƒã‚ï¼‰")
        return True

    return False

    
# ğŸ”½ ãµã‚ã‚‚ã“çµµæ–‡å­—ãƒªã‚¹ãƒˆã¨èªå°¾
FUWAMOKO_EMOJIS = r'[ğŸ¾ğŸ§¸ğŸŒ¸ğŸŒŸğŸ’•ğŸ’–âœ¨â˜ï¸ğŸŒ·ğŸ°ğŸŒ¼ğŸŒ™]'
FWA_GOBI = ["â™¡", "â™ª", "âœ¨", "ğŸŒ¸", "ğŸ¾", "ğŸ’–"]

# ãµã‚ã‚‚ã“å£èª¿å¤‰æ›è¾æ›¸ï¼ˆé•·ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã‹ã‚‰ï¼‰
fuwamoko_tone_map = [
    ("ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™", "ã‚ã‚ŠãŒã¨ğŸ°ğŸ’“"),
    ("ã‚ã‚ŠãŒã¨ã†", "ã‚ã‚ŠãŒã¨â™ª"),
    ("ã§ã™ã­", "ã ã­ã€œâœ¨"),
    ("ã§ã™ã‚ˆ", "ã ã‚ˆâ™¡"),
    ("ã§ã™", "ã ã‚ˆâ™¡"),
    ("ã¾ã™", "ã™ã‚‹ã‚ˆâ™ª"),
    ("ã¾ã—ãŸ", "ã—ãŸã‚ˆã€œğŸ’–"),
]

def clean_output(text):
    """è£…é£¾è¨˜å·ã‚„ç„¡æ„å‘³ãªå‡ºåŠ›ã‚’æµ„åŒ–"""
    text = re.sub(r'\n{2,}', '\n', text)
    text = re.sub(r'[^\w\sã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯ã€‚ã€ï¼ï¼Ÿ!?â™¡ï¼ˆï¼‰ã€Œã€â™ªã€œãƒ¼â€¦wç¬‘]+', '', text)
    text = re.sub(r'[ã€‚ã€ï¼ï¼Ÿ]{2,}', lambda m: m.group(0)[0], text)
    return text.strip()

def apply_fuwamoko_tone(reply):
    """ãµã‚ã‚‚ã“å£èª¿ã«å¤‰æ›"""
    for formal, soft in fuwamoko_tone_map:
        reply = reply.replace(formal, soft)
    return reply

def open_calm_reply(image_url, text="", context="ãµã‚ã‚‚ã“å…±æ„Ÿ", lang="ja"):
    NG_WORDS = globals()["EMOTION_TAGS"].get("nsfw_ng", [
        "åŠ å·¥è‚‰", "ãƒãƒ ", "ã‚½ãƒ¼ã‚»ãƒ¼ã‚¸", "ãƒ™ãƒ¼ã‚³ãƒ³", "ã‚µãƒ¼ãƒ¢ãƒ³", "ãŸã‚‰ã“", "æ˜å¤ªå­",
        "ãƒ‘ã‚¹ã‚¿", "ãƒ©ãƒ¼ãƒ¡ãƒ³", "å¯¿å¸", "ã†ã©ã‚“", "sushi", "sashimi", "salmon",
        "meat", "bacon", "ham", "sausage", "pasta", "noodle",
        "soft core", "NSFW", "è‚Œè‰²", "ä¸‹ç€", "è‚Œè¦‹ã›", "éœ²å‡º",
        "è‚Œãƒ•ã‚§ãƒ", "soft skin", "fetish"
    ])
    NG_PHRASES = [
        r"(?:æŠ•ç¨¿|ãƒ¦ãƒ¼ã‚¶ãƒ¼|ä¾‹æ–‡|æ“¬éŸ³èª|ãƒã‚¹ã‚¯ãƒƒãƒˆ|ãƒã‚¹ã‚±ãƒƒãƒˆ|ãƒ•ã‚©ãƒ¼ãƒ©ãƒ |è¿”äº‹|ä¼šè©±|å…±æ„Ÿ)",
        r"(?:ç™’ã—ç³»ã®ãµã‚ã‚‚ã“ãƒã‚¹ã‚³ãƒƒãƒˆ|æŠ•ç¨¿å†…å®¹ã«å¯¾ã—ã¦)",
        r"[â– #]{2,}",
        r"!{5,}", r"\?{5,}", r"[!ï¼Ÿ]{5,}",
        r"(?:(ãµã‚|ã‚‚ã“|ã‚‚ã¡|ã½ã“)\1{2,})",
        r"[â™ª~]{2,}",
        r"(#\w+){3,}",  # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°3å€‹ä»¥ä¸Š
        r"^[^\w\s]+$",  # çµµæ–‡å­—ç¾…åˆ—
        r"(\w+\s*,){3,}",  # å˜èªåˆ—
        r"[\*:\.]{2,}"  # è£…é£¾è¨˜å·é€£é–
    ]

    templates = deepcopy(ORIGINAL_TEMPLATES)
    if not check_template_integrity(templates):
        templates = auto_revert_templates(templates)
    audit_templates_changes(ORIGINAL_TEMPLATES, templates)

    NORMAL_TEMPLATES_JP = templates["NORMAL_TEMPLATES_JP"]
    SHONBORI_TEMPLATES_JP = templates["SHONBORI_TEMPLATES_JP"]
    MOGUMOGU_TEMPLATES_JP = templates["MOGUMOGU_TEMPLATES_JP"]
    NORMAL_TEMPLATES_EN = templates["NORMAL_TEMPLATES_EN"]
    MOGUMOGU_TEMPLATES_EN = templates["MOGUMOGU_TEMPLATES_EN"]
    COSMETICS_TEMPLATES_JP = templates["COSMETICS_TEMPLATES_JP"]
    COSMETICS_TEMPLATES_EN = templates["COSMETICS_TEMPLATES_EN"]
    CHARACTER_TEMPLATES_JP = templates["CHARACTER_TEMPLATES_JP"]
    CHARACTER_TEMPLATES_EN = templates["CHARACTER_TEMPLATES_EN"]

    detected_tags = []
    for tag, words in globals()["EMOTION_TAGS"].items():
        if any(word in text.lower() for word in words):
            detected_tags.append(tag)

    if "food" in detected_tags or any(word.lower() in text.lower() for word in NG_WORDS):
        logging.debug(f"ğŸ½ï¸ NGãƒ¯ãƒ¼ãƒ‰/é£Ÿäº‹æ¤œå‡º: {text[:40]}")
        return random.choice(MOGUMOGU_TEMPLATES_JP) if lang == "ja" else random.choice(MOGUMOGU_TEMPLATES_EN)
    elif "shonbori" in detected_tags:
        return random.choice(SHONBORI_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)
    elif "safe_cosmetics" in detected_tags:
        if lang == "ja":
            for cosmetic, templates in COSMETICS_TEMPLATES_JP.items():
                if cosmetic in text.lower():
                    return random.choice(templates)
        else:
            for cosmetic, templates in COSMETICS_TEMPLATES_EN.items():
                if any(word in text.lower() for word in globals()["EMOTION_TAGS"]["safe_cosmetics"]):
                    return random.choice(templates)
    elif any(tag in detected_tags for tag in globals()["SAFE_CHARACTER"]):
        if lang == "ja":
            for char_type, templates in CHARACTER_TEMPLATES_JP.items():
                if any(word in text.lower() for word in globals()["SAFE_CHARACTER"][char_type]):
                    return random.choice(templates)
        else:
            for char_type, templates in CHARACTER_TEMPLATES_EN.items():
                if any(word in text.lower() for word in globals()["SAFE_CHARACTER"][char_type]):
                    return random.choice(templates)
    elif any(word in text.lower() for word in globals()["GENERAL_TAGS"]):
        return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

    if not text.strip():
        text = "ã‚‚ãµã‚‚ãµã®ã†ã•ãã•ã‚“ã ã‚ˆã€œğŸ°"

    prompt = (
        "# ä¼šè©±ä¾‹\n"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼: ä»Šæ—¥å¯’ã™ãã¦å¸ƒå›£ã‹ã‚‰å‡ºã‚‰ã‚Œãªã„ã€œ\n"
        "è¿”ä¿¡: ã‚‚ãµã‚‚ãµã—ã¦ã‚ã£ãŸã¾ã‚ã†ã­ï¼â™¡âœ¨\n"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã­ã“ãŒè†ã«ä¹—ã£ã¦ããŸã€œ\n"
        "è¿”ä¿¡: ã‚ã£ãŸã‹ãã¦å¹¸ã›ã ã­ã€œğŸ¾ğŸ’•\n"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã½ã“ã½ã“æ˜Ÿç©ºï¼ğŸŒŸ\n"
        "è¿”ä¿¡: ã½ã“ã½ã“æ„Ÿã€ãŸã¾ã‚‰ã‚“ã­ï¼ğŸŒŸğŸ§¸\n"
        "# æœ¬æ–‡\n"
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {text.strip()[:100]}\n"
        "è¿”ä¿¡:\n"
    )
    logging.debug(f"ğŸ§ª ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç¢ºèª: {prompt}")

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=150).to(model.device)
    try:
        outputs = model.generate(
            **inputs,
            max_new_tokens=30,
            pad_token_id=tokenizer.pad_token_id,
            do_sample=True,
            temperature=0.65,
            top_k=50,
            top_p=0.9,
            no_repeat_ngram_size=2
        )
        raw_reply = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
        logging.debug(f"ğŸ§¸ Raw AIå‡ºåŠ›: {raw_reply}")

        reply = re.sub(r'^.*?è¿”ä¿¡:\s*', '', raw_reply, flags=re.DOTALL).strip()
        reply = clean_output(reply)
        reply = apply_fuwamoko_tone(reply)

        if not reply or len(reply) < 5:
            logging.warning(f"â­ï¸ SKIP: ç©ºã¾ãŸã¯çŸ­ã™ã: len={len(reply)}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: ç”Ÿæˆå¤±æ•—")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        # æ–‡ç« ãƒã‚§ãƒƒã‚¯ï¼ˆæ–‡æ³•ï¼‹æ“¬éŸ³èªã®ã¿ï¼‰
        if not re.search(r'(ã§ã™|ã¾ã™|ã­|ã‚ˆ|ã |ã‚‹|ãŸ|ã«|ã‚’|ãŒ|ã¯)', reply) or re.fullmatch(r'[ã-ã‚“ãƒ¼ã‚›ã‚œã€‚ã€\sã€Œã€ï¼ï¼Ÿ]+', reply):
            logging.warning(f"â­ï¸ SKIP: æ–‡ç« ä¸æˆç«‹: ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: æ–‡æ³•ä¸ååˆ†ã¾ãŸã¯æ“¬éŸ³èªã®ã¿")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        # é•·æ–‡ã‚«ãƒƒãƒˆ
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?ã€œ]+', reply)
        if len(sentences) >= 4:
            reply = "ã€‚".join(sentences[:3]) + "â€¦"
            logging.debug(f"ğŸ“ é•·æ–‡ã‚«ãƒƒãƒˆ: {reply}")

        if len(reply) < 15 or len(reply) > 35:
            logging.warning(f"â­ï¸ SKIP: é•·ã•ä¸é©åˆ‡: len={len(reply)}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: é•·ã•è¶…é")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        for bad in NG_PHRASES:
            if re.search(bad, reply):
                logging.warning(f"â­ï¸ SKIP: NGãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œå‡º: {bad}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: NGãƒ•ãƒ¬ãƒ¼ã‚º")
                return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        # æ–‡æœ«ã®ã€Œã€‚ã€ã¨çµµæ–‡å­—ã®èª¿æ•´
        needs_gobi = emoji_count < 2
        if reply.endswith("ã€‚") and needs_gobi:
            reply = reply[:-1]

        emoji_count = len(re.findall(FUWAMOKO_EMOJIS, reply))
        if emoji_count < 2:
            reply += random.choice(FWA_GOBI)
            emoji_count = len(re.findall(FUWAMOKO_EMOJIS, reply))
            logging.debug(f"ğŸ§¸ èªå°¾è£œå®Œ: {reply}")

        if emoji_count < 2 or emoji_count > 3:
            logging.warning(f"â­ï¸ SKIP: çµµæ–‡å­—æ•°ä¸é©åˆ‡: count={emoji_count}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: çµµæ–‡å­—ä¸è¶³")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        logging.info(f"ğŸ¦Š AIç”ŸæˆæˆåŠŸ: {reply}, é•·ã•: {len(reply)}, çµµæ–‡å­—: {emoji_count}")
        return reply
    except Exception as e:
        logging.error(f"âŒ AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)
        
        
def extract_valid_cid(ref):
    try:
        cid_candidate = str(ref.link) if hasattr(ref, 'link') else str(ref)
        if re.match(r'^baf[a-z0-9]{40,60}$', cid_candidate):
            return cid_candidate
        logging.error(f"âŒ ç„¡åŠ¹ãªCID: {cid_candidate}")
        return None
    except Exception as e:
        logging.error(f"âŒ CIDæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return None

def check_skin_ratio(img_pil_obj):
    try:
        if img_pil_obj is None:
            logging.debug("ç”»åƒãƒ‡ãƒ¼ã‚¿ç„¡åŠ¹ (PIL Imageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒNone)")
            return 0.0

        img_pil_obj = img_pil_obj.convert("RGB")
        img_np = cv2.cvtColor(np.array(img_pil_obj), cv2.COLOR_RGB2BGR)
        if img_np is None or img_np.size == 0:
            logging.error("âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ç„¡åŠ¹")
            return 0.0

        hsv_img = cv2.cvtColor(img_np, cv2.COLOR_BGR2HSV)

        # è‚Œè‰²ç¯„å›²ã‚’ã‚„ã‚„å³ã—ã‚ã«è¨­å®šï¼ˆãµã‚ã‚‚ã“ãƒ”ãƒ³ã‚¯ãƒ»ç™½ã®èª¤æ¤œçŸ¥é˜²æ­¢ï¼‰
        lower = np.array([5, 40, 60], dtype=np.uint8)
        upper = np.array([17, 170, 255], dtype=np.uint8)

        mask = cv2.inRange(hsv_img, lower, upper)
        skin_colors = img_np[mask > 0]

        if skin_colors.size > 0:
            avg_color = np.mean(skin_colors, axis=0)
            logging.debug(f"å¹³å‡è‚Œè‰²: BGR={avg_color}")
            if np.mean(avg_color) > 220:
                logging.debug("â†’ æ˜ã‚‹ã™ãã‚‹ã®ã§è‚Œè‰²ã§ã¯ãªãç™½ã¨ã¿ãªã™")
                return 0.0

        skin_area = np.sum(mask > 0)
        total_area = img_np.shape[0] * img_np.shape[1]
        skin_ratio = skin_area / total_area if total_area > 0 else 0.0
        logging.debug(f"è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}")
        return skin_ratio

    except Exception as e:
        logging.error(f"âŒ è‚Œè‰²è§£æã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return 0.0

def is_mutual_follow(client, handle):
    try:
        their_followers = client.get_followers(actor=handle, limit=100).followers
        their_followers = {f.handle for f in their_followers}
        my_followers = client.get_followers(actor=HANDLE, limit=100).followers
        my_followers = {f.handle for f in my_followers}
        return handle in my_followers and HANDLE in their_followers
    except Exception as e:
        logging.error(f"âŒ ç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼åˆ¤å®šã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def download_image_from_blob(cid, client, did=None):
    if not cid or not re.match(r'^baf[a-z0-9]{40,60}$', cid):
        logging.error(f"âŒ ç„¡åŠ¹ãªCID: {cid}")
        return None

    if client and did:
        try:
            logging.debug(f"ğŸ¦Š Blob APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹: CID={cid}, DID={did}")
            blob = client.com.atproto.repo.get_blob(cid=cid, did=did)
            logging.debug(f"Blob APIå–å¾—æˆåŠŸ: size={len(blob.data)} bytes")
            img_data = BytesIO(blob.data)
            try:
                img = Image.open(img_data)
                logging.info(f"ğŸŸ¢ Blobç”»åƒå½¢å¼={img.format}, ã‚µã‚¤ã‚º={img.size}")
                img.load()
                return img
            except (UnidentifiedImageError, OSError) as e:
                logging.error(f"âŒ Blobç”»åƒè§£æå¤±æ•—: {type(e).__name__}: {e}")
                return None
            except Exception as e:
                logging.error(f"âŒ Blobç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
                return None
        except Exception as e:
            logging.error(f"âŒ Blob APIã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

    did_safe = unquote(did) if did else None
    cdn_urls = [
        f"https://cdn.bsky.app/img/feed_thumbnail/plain/{quote(did_safe)}/{quote(cid)}@jpeg" if did_safe else None,
        f"https://cdn.bsky.app/img/feed_fullsize/plain/{quote(did_safe)}/{quote(cid)}@jpeg" if did_safe else None
    ]
    headers = {"User-Agent": "Mozilla/5.0"}

    for url in [u for u in cdn_urls if u]:
        try:
            logging.debug(f"ğŸ¦Š CDNãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹: CID={cid}, url={url}")
            response = requests.get(url, headers=headers, timeout=10, stream=True)
            response.raise_for_status()
            logging.debug(f"CDNå–å¾—æˆåŠŸ: ã‚µã‚¤ã‚º={len(response.content)} bytes")
            img_data = BytesIO(response.content)
            try:
                img = Image.open(img_data)
                logging.info(f"ğŸŸ¢ ç”»åƒå½¢å¼={img.format}, ã‚µã‚¤ã‚º={img.size}")
                img.load()
                return img
            except (UnidentifiedImageError, OSError) as e:
                logging.error(f"âŒ ç”»åƒè§£æå¤±æ•—: {type(e).__name__}: {e}, url={url}")
                return None
            except Exception as e:
                logging.error(f"âŒ ç”»åƒå–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}, url={url}")
                return None
        except requests.RequestException as e:
            logging.error(f"âŒ CDNå–å¾—å¤±æ•—: {type(e).__name__}: {e}, url={url}")
            continue

    logging.error("âŒ ç”»åƒå–å¾—å¤±æ•—")
    return None

def process_image(image_data, text="", client=None, post=None):
    if not hasattr(image_data, 'image') or not hasattr(image_data.image, 'ref'):
        logging.debug("ç”»åƒãƒ‡ãƒ¼ã‚¿æ§‹é€ ç•°å¸¸")
        return False

    cid = extract_valid_cid(image_data.image.ref)
    if not cid:
        return False

    try:
        author_did = post.post.author.did if post and hasattr(post, 'post') else None
        img = download_image_from_blob(cid, client, did=author_did)
        if img is None:
            logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒå–å¾—å¤±æ•—ï¼ˆãƒ­ã‚°ã¯ä¸Šè¨˜ï¼‰")
            return False

        # æ˜åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ã—ã¦ãƒˆãƒƒãƒ—ã‚«ãƒ©ãƒ¼æŠ½å‡º
        resized_img = img.resize((64, 64))
        hsv_img = cv2.cvtColor(np.array(resized_img), cv2.COLOR_RGB2HSV)
        bright_colors = [(r, g, b) for (r, g, b), (_, s, v) in zip(resized_img.getdata(), hsv_img.reshape(-1, 3)) if v > 160]
        color_counts = Counter(bright_colors)
        top_colors = color_counts.most_common(5)
        logging.debug(f"ãƒˆãƒƒãƒ—5ã‚«ãƒ©ãƒ¼ï¼ˆæ˜åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œï¼‰: {[(c[0], c[1]) for c in top_colors]}")

        fluffy_count = 0
        bright_color_count = 0
        for color, _ in top_colors:
            r, g, b = color
            if is_fluffy_color(r, g, b):
                fluffy_count += 1
            if r > 180 and g > 180 and b > 180:  # æ˜ã‚‹ã„è‰²ã‚«ã‚¦ãƒ³ãƒˆ
                bright_color_count += 1
        logging.debug(f"ãµã‚ã‚‚ã“è‰²ã‚«ã‚¦ãƒ³ãƒˆ: {fluffy_count}, æ˜ã‚‹ã„è‰²æ•°: {bright_color_count}")

        skin_ratio = check_skin_ratio(img)
        logging.debug(f"è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}, ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼æ•°: {fluffy_count}")

        if skin_ratio > 0.4 and fluffy_count == 0:
            logging.debug("è‚Œè‰²æ¯”ç‡é«˜ãã€ãµã‚ã‚‚ã“è‰²æ¤œå‡ºã‚¼ãƒ­â†’NG")
            return False
        elif skin_ratio > 0.4 and fluffy_count == 1 and bright_color_count < 3:
            logging.debug("è‚Œè‰²æ¯”ç‡é«˜ãã€ãµã‚ã‚‚ã“1è‰²ï¼‹æ˜è‰²å°‘ãªã‚â†’NGï¼ˆå˜ä¸€è‰²ç–‘ã„ï¼‰")
            return False
        elif skin_ratio > 0.4 and fluffy_count >= 1 and bright_color_count >= 3:
            logging.info("âš ï¸ è‚Œè‰²å¤šã„ãŒã€ãµã‚ã‚‚ã“1è‰²ï¼‹æ˜è‰²å¤šã‚ã§è¨±å®¹")
            return True
        elif fluffy_count >= 2:
            logging.info("ğŸŸ¢ ãµã‚ã‚‚ã“è‰²æ¤œå‡º")
            return True
        else:
            logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è‰²æ¡ä»¶ä¸è¶³")
            return False

        check_text = text.lower()
        try:
            if any(word in check_text for word in globals()["HIGH_RISK_WORDS"]):
                if skin_ratio < 0.4 and fluffy_count >= 2:
                    logging.info("ğŸŸ¢ é«˜ãƒªã‚¹ã‚¯ã ãŒæ¡ä»¶OK")
                    return True
                else:
                    logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: é«˜ãƒªã‚¹ã‚¯ï¼‹æ¡ä»¶NG")
                    return False
        except KeyError:
            logging.error("âŒ HIGH_RISK_WORDSæœªå®šç¾©ã€‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return False

    except Exception as e:
        logging.error(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def is_quoted_repost(post):
    try:
        actual_post = post.post if hasattr(post, 'post') else post
        record = getattr(actual_post, 'record', None)
        if record and hasattr(record, 'embed') and record.embed:
            embed = record.embed
            logging.debug(f"å¼•ç”¨ãƒªãƒã‚¹ãƒˆãƒã‚§ãƒƒã‚¯: {embed}")
            if hasattr(embed, 'record') and embed.record:
                logging.debug("å¼•ç”¨ãƒªãƒã‚¹ãƒˆæ¤œå‡ºï¼ˆrecordï¼‰")
                return True
            elif hasattr(embed, 'record') and hasattr(embed.record, 'record') and embed.record.record:
                logging.debug("å¼•ç”¨ãƒªãƒã‚¹ãƒˆæ¤œå‡ºï¼ˆrecordWithMediaï¼‰")
                return True
        return False
    except Exception as e:
        logging.error(f"âŒ å¼•ç”¨ãƒªãƒã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def load_reposted_uris():
    REPOSTED_FILE = "reposted_uris.txt"
    if os.path.exists(REPOSTED_FILE):
        try:
            with open(REPOSTED_FILE, 'r', encoding='utf-8') as f:
                uris = set(line.strip() for line in f if line.strip())
                logging.info(f"ğŸŸ¢ å†æŠ•ç¨¿URIèª­ã¿è¾¼ã¿: {len(uris)}ä»¶")
                return uris
        except Exception as e:
            logging.error(f"âŒ å†æŠ•ç¨¿URIèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            return set()
    return set()

def detect_language(client, handle):
    try:
        profile = client.get_profile(actor=handle)
        bio = profile.display_name.lower() + " " + getattr(profile, "description", "").lower()
        if any(kw in bio for kw in ["æ—¥æœ¬èª", "æ—¥æœ¬", "ã«ã»ã‚“", "japanese", "jp"]):
            return "ja"
        elif any(kw in bio for kw in ["english", "us", "uk", "en"]):
            return "en"
        return "ja"
    except Exception as e:
        logging.error(f"âŒ è¨€èªåˆ¤å®šã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return "ja"

def is_priority_post(text):
    return "@mirinchuuu" in text.lower()

def is_reply_to_self(post):
    reply = getattr(post.record, "reply", None) if hasattr(post, 'record') else None
    if reply and hasattr(reply, 'parent') and hasattr(reply.parent, 'uri'):
        return reply.parent.uri == post.post.uri
    return False

fuwamoko_uris = {}

def normalize_uri(uri):
    try:
        if not uri.startswith('at://'):
            uri = f"at://{uri.lstrip('/')}"
        parts = uri.split('/')
        if len(parts) >= 5:
            normalized = f"at://{parts[2]}/{parts[3]}/{parts[4]}"
            logging.debug(f"ğŸ¦Š URIæ­£è¦åŒ–: {uri} -> {normalized}")
            return normalized
        logging.warning(f"â­ï¸ URIæ­£è¦åŒ–å¤±æ•—: ä¸æ­£ãªå½¢å¼: {uri}")
        return uri
    except Exception as e:
        logging.error(f"âŒ URIæ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return uri

def validate_fuwamoko_file():
    if not os.path.exists(FUWAMOKO_FILE):
        logging.info("ğŸŸ¢ ãµã‚ã‚‚ã“å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        with open(FUWAMOKO_FILE, 'w', encoding='utf-8') as f:
            f.write("")
        return True
    try:
        with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for line in lines:
                clean_line = line.strip()
                if not clean_line:
                    continue
                if not re.match(r'^at://[^|]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}(?:\d{3})?\+\d{2}:\d{2}$', clean_line):
                    logging.error(f"âŒ ç„¡åŠ¹ãªå±¥æ­´è¡Œ: {repr(clean_line)}")
                    return False
        return True
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def repair_fuwamoko_file():
    temp_file = FUWAMOKO_FILE + ".tmp"
    valid_lines = []
    if os.path.exists(FUWAMOKO_FILE):
        try:
            with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    clean_line = line.strip()
                    if not clean_line:
                        continue
                    if re.match(r'^at://[^|]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}(?:\d{3})?\+\d{2}:\d{2}$', clean_line):
                        valid_lines.append(line)
                    else:
                        logging.warning(f"â­ï¸ ç ´æè¡Œã‚¹ã‚­ãƒƒãƒ—: {repr(clean_line)}")
            with open(temp_file, 'w', encoding='utf-8') as f:
                f.writelines(valid_lines)
            os.replace(temp_file, FUWAMOKO_FILE)
            logging.info(f"ğŸŸ¢ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©å®Œäº†: {len(valid_lines)}ä»¶ä¿æŒ")
        except Exception as e:
            logging.error(f"âŒ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            if os.path.exists(temp_file):
                os.remove(temp_file)
    else:
        with open(FUWAMOKO_FILE, 'w', encoding='utf-8') as f:
            f.write("")
        logging.info("ğŸŸ¢ æ–°è¦å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")

def load_fuwamoko_uris():
    global fuwamoko_uris
    fuwamoko_uris.clear()
    if not validate_fuwamoko_file():
        logging.warning("âš ï¸ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ç ´æã€‚ä¿®å¾©ã‚’è©¦ã¿ã¾ã™ã€‚")
        repair_fuwamoko_file()
    try:
        with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
            logging.info(f"ğŸŸ¢ ãµã‚ã‚‚ã“å±¥æ­´ã‚µã‚¤ã‚º: {len(content)} bytes")
            if content.strip():
                for line in content.splitlines():
                    if line.strip():
                        try:
                            uri, timestamp = line.strip().split("|", 1)
                            normalized_uri = normalize_uri(uri)
                            fuwamoko_uris[normalized_uri] = datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
                            logging.debug(f"ğŸ¦Š å±¥æ­´èª­ã¿è¾¼ã¿: {normalized_uri}")
                        except ValueError as e:
                            logging.warning(f"â­ï¸ ç ´æè¡Œã‚¹ã‚­ãƒƒãƒ—: {repr(line.strip())}: {e}")
                            continue
            logging.info(f"ğŸŸ¢ ãµã‚ã‚‚ã“URIèª­ã¿è¾¼ã¿: {len(fuwamoko_uris)}ä»¶")
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        fuwamoko_uris.clear()

def save_fuwamoko_uri(uri, indexed_at):
    global fuwamoko_uris
    normalized_uri = normalize_uri(uri)
    lock = filelock.FileLock(FUWAMOKO_LOCK, timeout=5.0)
    try:
        with lock:
            logging.debug(f"ğŸ¦Š ãƒ­ãƒƒã‚¯å–å¾—: {FUWAMOKO_LOCK}")
            if normalized_uri in fuwamoko_uris and (datetime.now(timezone.utc) - fuwamoko_uris[normalized_uri]).total_seconds() < 24 * 3600:
                logging.debug(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: 24æ™‚é–“ä»¥å†…: {normalized_uri}")
                return
            if isinstance(indexed_at, str):
                indexed_at = datetime.fromisoformat(indexed_at.replace("Z", "+00:00"))
            with open(FUWAMOKO_FILE, 'a', encoding='utf-8') as f:
                f.write(f"{normalized_uri}|{indexed_at.isoformat()}\n")
            fuwamoko_uris[normalized_uri] = indexed_at
            logging.info(f"ğŸŸ¢ å±¥æ­´ä¿å­˜: {normalized_uri}")
            with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                last_line = lines[-1].strip() if lines else ""
                if last_line.startswith(normalized_uri):
                    logging.debug(f"ğŸ¦Š å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: æœ€å¾Œã®è¡Œ={last_line}")
                else:
                    logging.error(f"âŒ å±¥æ­´ä¿å­˜å¤±æ•—: æœ€å¾Œã®è¡Œ={last_line}")
            load_fuwamoko_uris()
    except filelock.Timeout:
        logging.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {FUWAMOKO_LOCK}")
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def load_session_string():
    try:
        if os.path.exists(SESSION_FILE):
            with open(SESSION_FILE, 'r', encoding='utf-8') as f:
                return f.read().strip()
        return None
    except Exception as e:
        logging.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return None

def save_session_string(session_str):
    try:
        with open(SESSION_FILE, 'w', encoding='utf-8') as f:
            f.write(session_str)
    except Exception as e:
        logging.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def has_image(post):
    try:
        actual_post = post.post if hasattr(post, 'post') else post
        if not hasattr(actual_post, 'record') or not hasattr(actual_post.record, 'embed'):
            return False
        embed = actual_post.record.embed
        return (
            (hasattr(embed, 'images') and embed.images) or
            (hasattr(embed, 'record') and hasattr(embed.record, 'embed') and hasattr(embed.record.embed, 'images') and embed.record.embed.images) or
            (getattr(embed, '$type', '') == 'app.bsky.embed.recordWithMedia' and hasattr(embed, 'media') and hasattr(embed.media, 'images') and embed.media.images)
        )
    except Exception as e:
        logging.error(f"âŒ ç”»åƒãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def process_post(post_data, client, fuwamoko_uris, reposted_uris):
    try:
        actual_post = post_data.post if hasattr(post_data, 'post') else post_data
        uri = str(actual_post.uri)
        post_id = uri.split('/')[-1]
        text = getattr(actual_post.record, 'text', '') if hasattr(actual_post.record, 'text') else ''

        is_reply = hasattr(actual_post.record, 'reply') and actual_post.record.reply is not None
        if is_reply and not (is_priority_post(text) or is_reply_to_self(post_data)):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãƒªãƒ—ãƒ©ã‚¤ï¼ˆé@mirinchuuu/éè‡ªå·±ï¼‰: {text[:20]} ({post_id})")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒªãƒ—ãƒ©ã‚¤: {post_id}")
            return False

        print(f"ğŸ¦Š POSTå‡¦ç†é–‹å§‹: @{actual_post.author.handle} ({post_id})")
        logging.info(f"ğŸŸ¢ POSTå‡¦ç†é–‹å§‹: @{actual_post.author.handle} ({post_id})")
        normalized_uri = normalize_uri(uri)
        if normalized_uri in fuwamoko_uris:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: æ—¢å­˜æŠ•ç¨¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: æ—¢å­˜æŠ•ç¨¿: {post_id}")
            return False
        if actual_post.author.handle == HANDLE:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è‡ªåˆ†ã®æŠ•ç¨¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: è‡ªåˆ†ã®æŠ•ç¨¿: {post_id}")
            return False
        if is_quoted_repost(post_data):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: å¼•ç”¨ãƒªãƒã‚¹ãƒˆ: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: å¼•ç”¨ãƒªãƒã‚¹ãƒˆ: {post_id}")
            return False
        if post_id in reposted_uris:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: å†æŠ•ç¨¿æ¸ˆã¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: å†æŠ•ç¨¿æ¸ˆã¿: {post_id}")
            return False

        author = actual_post.author.handle
        indexed_at = actual_post.indexed_at

        if not has_image(post_data):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒãªã—: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒãªã—: {post_id}")
            return False

        image_data_list = []
        embed = getattr(actual_post.record, 'embed', None)
        if embed:
            if hasattr(embed, 'images') and embed.images:
                image_data_list.extend(embed.images)
            elif hasattr(embed, 'record') and hasattr(embed.record, 'embed') and hasattr(embed.record.embed, 'images'):
                image_data_list.extend(embed.record.embed.images)
            elif getattr(embed, '$type', '') == 'app.bsky.embed.recordWithMedia' and hasattr(embed, 'media') and hasattr(embed.media, 'images'):
                image_data_list.extend(embed.media.images)

        if not is_mutual_follow(client, author):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: éç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼: @{author} ({post_id})")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: éç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼: @{author} ({post_id})")
            return False

        for i, image_data in enumerate(image_data_list):
            try:
                print(f"ğŸ¦Š ç”»åƒå‡¦ç†é–‹å§‹: {i+1}/{len(image_data_list)} ({post_id})")
                logging.debug(f"ç”»åƒå‡¦ç†é–‹å§‹: {i+1}/{len(image_data_list)} ({post_id})")
                if process_image(image_data, text, client=client, post=post_data):
                    if random.random() > 0.5:
                        print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆ50%ï¼‰: {post_id}")
                        logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒ©ãƒ³ãƒ€ãƒ : {post_id}")
                        save_fuwamoko_uri(uri, indexed_at)
                        return False
                    lang = detect_language(client, author)
                    reply_text = open_calm_reply("", text, lang=lang)
                    if not reply_text:
                        print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è¿”ä¿¡ç”Ÿæˆå¤±æ•—: {post_id}")
                        logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: è¿”ä¿¡ç”Ÿæˆå¤±æ•—: {post_id}")
                        save_fuwamoko_uri(uri, indexed_at)
                        return False
                    root_ref = models.ComAtprotoRepoStrongRef.Main(
                        uri=uri,
                        cid=actual_post.cid
                    )
                    parent_ref = models.ComAtprotoRepoStrongRef.Main(
                        uri=uri,
                        cid=actual_post.cid
                    )
                    reply_ref = models.AppBskyFeedPost.ReplyRef(
                        root=root_ref,
                        parent=parent_ref
                    )
                    print(f"ğŸ¦Š è¿”ä¿¡é€ä¿¡: @{author}: {reply_text} ({post_id})")
                    logging.debug(f"è¿”ä¿¡é€ä¿¡: @{author}: {reply_text} ({post_id})")
                    client.send_post(text=reply_text, reply_to=reply_ref)
                    save_fuwamoko_uri(uri, indexed_at)
                    print(f"âœ… SUCCESS: è¿”ä¿¡æˆåŠŸ: @{author} ({post_id})")
                    logging.info(f"ğŸŸ¢ è¿”ä¿¡æˆåŠŸ: @{author} ({post_id})")
                    return True
                else:
                    print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãµã‚ã‚‚ã“ç”»åƒã§ãªã„: {post_id} (ç”»åƒ {i+1})")
                    logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãµã‚ã‚‚ã“ç”»åƒã§ãªã„: {post_id} (ç”»åƒ {i+1})")
                    save_fuwamoko_uri(uri, indexed_at)
                    return False
            except Exception as e:
                print(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri}, cid={actual_post.cid})")
                logging.error(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri}, cid={actual_post.cid})")
                save_fuwamoko_uri(uri, indexed_at)
                return False
    except Exception as e:
        print(f"âŒ æŠ•ç¨¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri})")
        logging.error(f"âŒ æŠ•ç¨¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri})")
        save_fuwamoko_uri(uri, indexed_at)
        return False

def run_once():
    try:
        client = Client()
        session_str = load_session_string()
        if session_str:
            client.login(session_string=session_str)
            print(f"ğŸš€âœ¨ START: ãµã‚ã‚‚ã“Botèµ·å‹•ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨ï¼‰")
            logging.info("ğŸŸ¢ Botèµ·å‹•: ã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨")
        else:
            client.login(HANDLE, APP_PASSWORD)
            session_str = client.export_session_string()
            save_session_string(session_str)
            print(f"ğŸš€âœ¨ START: ãµã‚ã‚‚ã“Botèµ·å‹•ï¼ˆæ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰")
            logging.info("ğŸŸ¢ Botèµ·å‹•: æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³")

        print(f"ğŸ¦Š INFO: Botç¨¼åƒä¸­: {HANDLE}")
        logging.info(f"ğŸŸ¢ Botç¨¼åƒä¸­: {HANDLE}")
        load_fuwamoko_uris()
        reposted_uris = load_reposted_uris()

        timeline = client.get_timeline(limit=50)
        feed = timeline.feed
        for post in sorted(feed, key=lambda x: x.post.indexed_at, reverse=True):
            try:
                thread_response = client.get_post_thread(uri=str(post.post.uri), depth=2)
                process_post(thread_response.thread, client, fuwamoko_uris, reposted_uris)
            except Exception as e:
                print(f"âŒ ã‚¹ãƒ¬ãƒƒãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (URI: {post.post.uri})")
                logging.error(f"âŒ ã‚¹ãƒ¬ãƒƒãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (URI: {post.post.uri})")
            time.sleep(1.0)
    except Exception as e:
        print(f"âŒ Botå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        logging.error(f"âŒ Botå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

if __name__ == "__main__":
    try:
        load_dotenv()
        run_once()
    except Exception as e:
        logging.error(f"âŒ Botèµ·å‹•ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")