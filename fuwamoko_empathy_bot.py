# ğŸ”½ ğŸ“¦ Pythonã®æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from datetime import datetime, timezone
import os
import time
import random
import requests
from io import BytesIO
import filelock
import re
import logging
import cv2
import numpy as np
from urllib.parse import quote, unquote
from PIL import Image, UnidentifiedImageError, ImageFile
from copy import deepcopy
import json

# ğŸ”½ ğŸŒ± å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer
from collections import Counter
import torch

# ğŸ”½ ğŸ“¡ atprotoé–¢é€£
from atproto import Client, models

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(filename='debug.log', level=logging.DEBUG, format='%(asctime)s %(message)s', encoding='utf-8')
logging.getLogger().addHandler(logging.StreamHandler())

# PILã®ã‚¨ãƒ©ãƒ¼æŠ‘åˆ¶
ImageFile.LOAD_TRUNCATED_IMAGES = True

# ğŸ”½ ğŸ§  Transformersç”¨è¨­å®š
MODEL_NAME = "cyberagent/open-calm-small"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=".cache")
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    cache_dir=".cache",
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto"
)
tokenizer.pad_token = tokenizer.eos_token

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
HANDLE = os.environ.get("HANDLE")
APP_PASSWORD = os.environ.get("APP_PASSWORD")
SESSION_FILE = "session_string.txt"
FUWAMOKO_FILE = "fuwamoko_empathy_uris.txt"
FUWAMOKO_LOCK = "fuwamoko_empathy_uris.lock"

# ğŸ”½ ãƒ†ãƒ³ãƒ—ãƒ¬ä¿è­·ï¼ˆãƒãƒ£ãƒƒãƒ”ãƒ¼æ†²ç« ï¼‰
LOCK_TEMPLATES = True
ORIGINAL_TEMPLATES = {
    "NORMAL_TEMPLATES_JP": [
        "ã†ã‚“ã†ã‚“ã€ã‹ã‚ã„ã„ã­ï¼ç™’ã•ã‚ŒãŸã‚ˆğŸ¾ğŸ’–",
        "ã‚ˆã‹ã£ãŸã­ã€œï¼ãµã‚ãµã‚ã ã­ğŸŒ¸ğŸ§¸",
        "ãˆã¸ã£ã€ãƒ¢ãƒ•ãƒ¢ãƒ•ã§ç™’ã—MAXï¼ğŸ’",
        "ã†ã‚ã£ï¼å¯æ„›ã™ãã‚‹ã‚ˆğŸ¾ğŸŒ·",
        "ãµã‚ãµã‚ã ã­ã€å…ƒæ°—å‡ºãŸï¼ğŸ’«ğŸ§¸"
    ],
    "SHONBORI_TEMPLATES_JP": [
        "ãã£ã‹â€¦ãã‚…ãƒ¼ã£ã¦ã—ã¦ã‚ã’ã‚‹ã­ğŸ¾ğŸ’•",
        "å…ƒæ°—å‡ºã—ã¦ã­ã€ãµã‚ã‚‚ã“ãƒ‘ãƒ¯ãƒ¼é€ã‚‹ã‚ˆï¼ğŸ§¸âœ¨",
        "ã¤ã‚‰ã„ã¨ãã“ãã€ãµã‚ãµã‚ã«åŒ…ã¾ã‚Œã¦â€¦ğŸ°â˜ï¸",
        "ç„¡ç†ã—ãªã„ã§ã­ã€ãã£ã¨å¯„ã‚Šæ·»ã†ã‚ˆğŸ§¸ğŸŒ¸"
    ],
    "MOGUMOGU_TEMPLATES_JP": [
        "ã†ãƒ¼ã‚“â€¦ã“ã‚Œã¯ç™’ã—ã‚ˆã‚Šç¾å‘³ã—ãã†ï¼ŸğŸ¾ğŸ’­",
        "ã‚‚ãã‚‚ãã—ã¦ã‚‹ã‘ã©â€¦ãµã‚ã‚‚ã“ã˜ã‚ƒãªã„ã‹ãªï¼ŸğŸ¤”",
        "ã¿ã‚Šã‚“ã¦ã‚ƒã€ãŠè…¹ç©ºã„ã¦ãã¡ã‚ƒã£ãŸâ€¦é£Ÿãƒ¬ãƒï¼ŸğŸ½ï¸ğŸ’¬"
    ],
    "NORMAL_TEMPLATES_EN": [
        "Wow, so cute! Feels good~ ğŸ¾ğŸ’–",
        "Nice! So fluffy~ ğŸŒ¸ğŸ§¸",
        "Great! Healing vibes! ğŸ’",
        "Amazing! Thanks for the fluff! ğŸ¾ğŸŒ·"
    ],
    "MOGUMOGU_TEMPLATES_EN": [
        "Hmmm... looks tasty, but maybe not so fluffy? ğŸ¾ğŸ’­",
        "So yummy-looking... but is this a snack or a friend? ğŸ¤”ğŸ½ï¸",
        "This might be food, not a fluffy cutie... ğŸ½ï¸ğŸ’­",
        "Adorable! But maybe not a fluffy buddy? ğŸ‘ğŸ’¬"
    ],
    "COSMETICS_TEMPLATES_JP": {
        "ãƒªãƒƒãƒ—": ["ã“ã®ãƒªãƒƒãƒ—å¯æ„›ã„ã€œğŸ’„ğŸ’–", "è‰²å‘³ãŒç´ æ•µã™ãã¦ã†ã£ã¨ã‚Šã—ã¡ã‚ƒã†ğŸ’‹"],
        "é¦™æ°´": ["ã“ã®é¦™ã‚Šã€çµ¶å¯¾ãµã‚ã‚‚ã“ã ã‚ˆã­ğŸŒ¸", "ã„ã„åŒ‚ã„ã€œï¼ğŸ’•"],
        "ãƒã‚¤ãƒ«": ["ãã®ãƒã‚¤ãƒ«ã€ã‚­ãƒ©ã‚­ãƒ©ã—ã¦ã¦æœ€é«˜ğŸ’…âœ¨", "ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼ã§ç´ æ•µã€œğŸ’–"]
    },
    "COSMETICS_TEMPLATES_EN": {
        "lip": ["That lipstick is so cute~ ğŸ’„ğŸ’–", "The color is dreamy, Iâ€™m in love ğŸ’‹"],
        "perfume": ["I bet that perfume smells fluffy and sweet ğŸŒ¸", "I can almost smell it~ so lovely! ğŸŒ¼"],
        "nail": ["That nail art is sparkly and perfect ğŸ’…âœ¨", "Fluffy colors make it so pretty ğŸ’–"]
    },
    "CHARACTER_TEMPLATES_JP": {
        "ã‚¢ãƒ‹ãƒ¡": ["ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ãŒãƒ¢ãƒ•ãƒ¢ãƒ•ï¼ğŸ’•", "ã¾ã‚‹ã§å¤¢ã®ä¸–ç•Œã®ä½äººğŸŒŸ"],
        "æ¼«ç”»": ["ã‚³ãƒã‹ã‚‰é£›ã³å‡ºã—ã¦ããŸã¿ãŸã„ï¼ğŸ“–âœ¨", "ã“ã®ã‚¿ãƒƒãƒã€ã‚ã¡ã‚ƒå¥½ã¿â€¦ï¼ğŸ’˜"],
        "ã‚¤ãƒ©ã‚¹ãƒˆ": ["ç·šã®å„ªã—ã•ã«ç™’ã•ã‚Œã‚‹â€¦ğŸ–‹ï¸ğŸŒ¼", "è‰²ã¥ã‹ã„ãŒã»ã‚“ã¨ç´ æ•µğŸ’–"],
        "ä¸€æ¬¡å‰µä½œ": ["ã‚ªãƒªã‚­ãƒ£ãƒ©å°Šã„â€¦ğŸ¥ºâœ¨", "ã“ã®å­ã ã‘ã®ä¸–ç•Œè¦³ãŒã‚ã‚‹ã­ğŸ’–"],
        "äºŒæ¬¡å‰µä½œ": ["ã“ã®è§£é‡ˆã€å¤©æ‰ã™ãã‚‹â€¦ï¼ğŸ™Œ", "åŸä½œæ„›ãŒä¼ã‚ã£ã¦ãã‚‹ã‚ˆâœ¨"]
    },
    "CHARACTER_TEMPLATES_EN": {
        "anime": ["That anime character looks so fluffy! ğŸ’•", "Like someone straight out of a dream world~ ğŸŒŸ"],
        "manga": ["They look like they just stepped out of a manga panel! ğŸ“–âœ¨", "I love the vibe of this linework! ğŸ’˜"],
        "illustration": ["The softness in these lines is so comforting~ ğŸ–‹ï¸ğŸŒ¼", "The colors are simply beautiful! ğŸ’–"],
        "oc": ["Your OC is preciousâ€¦ ğŸ¥ºâœ¨", "They have such a unique and magical world of their own ğŸ’–"],
        "fanart": ["Your interpretation is genius! ğŸ™Œ", "I can feel your love for the original work âœ¨"]
    }
}

# ğŸ”½ ã‚°ãƒ­ãƒ¼ãƒãƒ«è¾æ›¸åˆæœŸåŒ–
try:
    _ = globals()["EMOTION_TAGS"]
except KeyError:
    logging.error("âš ï¸ EMOTION_TAGSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["EMOTION_TAGS"] = {
        "fuwamoko": ["ãµã‚ãµã‚", "ã‚‚ã“ã‚‚ã“", "ã‚‚ãµã‚‚ãµ", "fluffy", "fluff", "fluffball", "ãµã‚ã‚‚ã“",
                     "ã½ã‚ˆã½ã‚ˆ", "ã‚„ã‚ã‚„ã‚", "ãã‚…ã‚‹ãã‚…ã‚‹", "ã½ãµã½ãµ", "ãµã‚ã‚‚ãµ", "é›²"],
        "neutral": ["ã‹ã‚ã„ã„", "cute", "adorable", "æ„›ã—ã„"],
        "shonbori": ["ã—ã‚‡ã‚“ã¼ã‚Š", "ã¤ã‚‰ã„", "ã‹ãªã—ã„", "ã•ã³ã—ã„", "ç–²ã‚ŒãŸ", "ã¸ã“ã‚“ã ", "æ³£ããã†"],
        "food_ng": ["è‚‰", "ã”é£¯", "é£¯", "ãƒ©ãƒ³ãƒ", "ãƒ‡ã‚£ãƒŠãƒ¼", "ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°", "ã”ã¯ã‚“", "åµ", "ãŸã¾ã”", "ãŠã«ãã‚Š",
                    "ãŠã„ã—ã„", "ã†ã¾ã„", "ç¾å‘³", "ã„ãŸã ãã¾ã™", "ãŸã¹ãŸ", "é£Ÿ", "ã”ã¡ãã†", "ã”é¦³èµ°",
                    "ã¾ãã‚", "åˆºèº«", "ãƒãƒ¼ã‚º", "ã‚¹ãƒŠãƒƒã‚¯", "yummy", "delicious", "ã‚¹ãƒ¼ãƒ—",
                    "å‘³å™Œæ±", "ã‚«ãƒ«ãƒœãƒŠãƒ¼ãƒ©", "é‹", "éºº", "ãƒ‘ãƒ³", "ãƒˆãƒ¼ã‚¹ãƒˆ", "è±†è…",
                    "ã‚«ãƒ•ã‚§", "ã‚¸ãƒ¥ãƒ¼ã‚¹", "ãƒŸãƒ«ã‚¯", "ãƒ‰ãƒªãƒ³ã‚¯", "ãŠã‚„ã¤", "é£Ÿäº‹", "æœé£Ÿ", "å¤•é£Ÿ", "æ˜¼é£Ÿ"],
        "nsfw_ng": ["é…’", "ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«", "ãƒ“ãƒ¼ãƒ«", "ãƒ¯ã‚¤ãƒ³", "é…ãƒã‚¤", "ã‚«ã‚¯ãƒ†ãƒ«", "ãƒã‚¤ãƒœãƒ¼ãƒ«", "æ¢…é…’",
                    "soft core", "NSFW", "è‚Œè‰²", "ä¸‹ç€", "è‚Œè¦‹ã›", "éœ²å‡º", "è‚Œãƒ•ã‚§ãƒ", "soft skin", "fetish",
                    "nude", "naked", "lewd", "18+", "sex", "uncensored",
                    "Hã‚«ãƒƒãƒ—", "å‰åŸ", "é¢¨ä¿—", "ãƒ©ãƒ³ã‚¸ã‚§ãƒªãƒ¼", "ãŠã£ã±ã„", "ã‚»ã‚¯ã‚·ãƒ¼", "æŒ‘ç™º", "è°·é–“", "èƒ¸å…ƒ", "ä¹³", "æ°´ç€å§¿", "ã‚¨ãƒ­", "ãˆã¡ãˆã¡", "ã±ã„"]
    }

try:
    _ = globals()["SAFE_CHARACTER"]
except KeyError:
    logging.error("âš ï¸ SAFE_CHARACTERæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["SAFE_CHARACTER"] = {
        "ã‚¢ãƒ‹ãƒ¡": ["ã‚¢ãƒ‹ãƒ¡", "anime", "anime art", "ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©"],
        "æ¼«ç”»": ["æ¼«ç”»", "ãƒãƒ³ã‚¬", "manga", "comic"],
        "ã‚¤ãƒ©ã‚¹ãƒˆ": ["ã‚¤ãƒ©ã‚¹ãƒˆ", "illustration", "drawing", "ã‚¹ã‚±ãƒƒãƒ", "art", "è½æ›¸ã"],
        "ä¸€æ¬¡å‰µä½œ": ["ä¸€æ¬¡å‰µä½œ", "ã‚ªãƒªã‚­ãƒ£ãƒ©", "ã‚ªãƒªã‚¸ãƒŠãƒ«", "oc", "original character", "my oc"],
        "äºŒæ¬¡å‰µä½œ": ["äºŒæ¬¡å‰µä½œ", "fanart", "fan art", "FA", "fandom art", "åŸä½œã‚­ãƒ£ãƒ©", "åŸä½œå†ç¾", "æ¨ã—ã‚­ãƒ£ãƒ©"]
    }

try:
    _ = globals()["GENERAL_TAGS"]
except KeyError:
    logging.error("âš ï¸ GENERAL_TAGSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["GENERAL_TAGS"] = ["ã‚­ãƒ£ãƒ©", "æ¨ã—"]

try:
    _ = globals()["HIGH_RISK_WORDS"]
except KeyError:
    logging.error("âš ï¸ HIGH_RISK_WORDSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["HIGH_RISK_WORDS"] = ["ã‚‚ã¡ã‚‚ã¡", "ã·ã«ã·ã«", "ã·ã‚ˆã·ã‚ˆ", "ã‚„ã‚ã‚‰ã‹ã„", "ã‚€ã«ã‚…ã‚€ã«ã‚…", "ã‚¨ãƒ­", "ãˆã£ã¡"]

# å„ªå…ˆé †ä½
PRIORITY_ORDER = ["äºŒæ¬¡å‰µä½œ", "ä¸€æ¬¡å‰µä½œ", "ã‚¢ãƒ‹ãƒ¡", "æ¼«ç”»", "ã‚¤ãƒ©ã‚¹ãƒˆ"]

# ãƒ†ãƒ³ãƒ—ãƒ¬ç›£æŸ»ãƒ­ã‚°
TEMPLATE_AUDIT_LOG = "template_audit_log.txt"

def audit_templates_changes(old, new):
    try:
        if old != new:
            with open(TEMPLATE_AUDIT_LOG, "a", encoding="utf-8") as f:
                f.write(json.dumps({
                    "timestamp": datetime.now().isoformat(),
                    "before": old,
                    "after": new
                }, ensure_ascii=False, indent=2) + "\n")
            logging.warning("âš ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬å¤‰æ›´æ¤œå‡º")
    except Exception as e:
        logging.error(f"âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ç›£æŸ»ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def check_template_integrity(templates):
    if not LOCK_TEMPLATES:
        logging.warning("âš ï¸ LOCK_TEMPLATESç„¡åŠ¹ã€æ”¹å¤‰ãƒªã‚¹ã‚¯")
        return False
    for key in ORIGINAL_TEMPLATES:
        if templates.get(key) != ORIGINAL_TEMPLATES[key]:
            logging.error(f"âš ï¸ {key} æ”¹å¤‰æ¤œå‡ºã€å¾©å…ƒæ¨å¥¨")
            return False
    return True

def auto_revert_templates(templates):
    if LOCK_TEMPLATES:
        for key in ORIGINAL_TEMPLATES:
            templates[key] = deepcopy(ORIGINAL_TEMPLATES[key])
        logging.info("âœ… ãƒ†ãƒ³ãƒ—ãƒ¬å¾©å…ƒå®Œäº†")
        return templates
    return templates

fuwamoko_tone_map = [
    ("ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™", "ã‚ã‚ŠãŒã¨ğŸ°ğŸ’“"),
    ("ã‚ã‚ŠãŒã¨ã†", "ã‚ã‚ŠãŒã¨â™ª"),
    ("ã§ã™ã­", "ã ã­ã€œâœ¨"),
    ("ã§ã™ã‚ˆ", "ã ã‚ˆâ™¡"),
    ("ã§ã™", "ã ã‚ˆâ™¡"),
    ("ã¾ã™", "ã™ã‚‹ã‚ˆâ™ª"),
    ("ã¾ã—ãŸ", "ã—ãŸã‚ˆã€œğŸ’–"),
]

def apply_fuwamoko_tone(reply):
    for formal, soft in fuwamoko_tone_map:
        reply = reply.replace(formal, soft)
    reply = re.sub(r'(ğŸ°ğŸ’“)\.', r'\1', reply)  # å¥ç‚¹ã¨çµµæ–‡å­—ã®ç•°å¸¸ä¿®æ­£
    return reply

def is_fluffy_color(r, g, b, bright_colors):
    logging.debug(f"ğŸ§ª è‰²åˆ¤å®š: RGB=({r}, {g}, {b})")
    hsv = cv2.cvtColor(np.array([[[r, g, b]]], dtype=np.uint8), cv2.COLOR_RGB2HSV)[0][0]
    h, s, v = hsv
    logging.debug(f"HSV=({h}, {s}, {v})")

    # é£Ÿå“è‰²ç¯„å›²ï¼ˆãƒãƒ /åµ/ãŠã«ãã‚Š/è±†è…ã€æ¡ƒèŠ±é™¤å¤–ï¼‰
    if ((150 <= r <= 200 and 150 <= g <= 200 and 150 <= b <= 200) or  # ãƒãƒ /åµ
        (220 <= r <= 250 and 220 <= g <= 250 and 210 <= b <= 230) or  # ãŠã«ãã‚Š
        (230 <= r <= 255 and 200 <= g <= 230 and 130 <= b <= 160) or  # è±†è…
        (r == 255 and g == 255 and b == 255)):                       # ç´”ç™½
        logging.debug("é£Ÿå“è‰²ï¼ˆãƒãƒ /åµ/ãŠã«ãã‚Š/è±†è…/ç´”ç™½ï¼‰æ¤œå‡ºã€ãµã‚ã‚‚ã“ã¨ã¿ãªã•ãªã„")
        return False

    # ç™½ç³»ï¼ˆæ˜ã‚‹ã•v > 130ã€å˜è‰²é–¾å€¤10ï¼‰
    if r > 180 and g > 180 and b > 180 and v > 130:
        if bright_colors and len(bright_colors) > 0:
            colors = np.array(bright_colors)
            if np.std(colors, axis=0).max() < 10:
                logging.debug("å˜è‰²ç™½ç³»ã€ãµã‚ã‚‚ã“ã¨ã¿ãªã•ãªã„")
                return False
        logging.debug("ç™½ç³»æ¤œå‡ºï¼ˆæ˜ã‚‹ã•OKã€ãƒ”ãƒ³ã‚¯å¯„ã‚Šå«ã‚€ï¼‰")
        return True

    # ãƒ”ãƒ³ã‚¯ç³»ï¼ˆæ¡ƒèŠ±å„ªå…ˆï¼‰
    if (r > 200 and g < 170 and b > 170 and v > 130) or \
       (220 <= r <= 240 and 220 <= g <= 240 and 230 <= b <= 250):  # #232, 236, 247 å¯¾å¿œ
        logging.debug("ãƒ”ãƒ³ã‚¯ç³»æ¤œå‡ºï¼ˆæ¡ƒèŠ±å„ªå…ˆã€æ˜ã‚‹ã•OKï¼‰")
        return True

    # ã‚¯ãƒªãƒ¼ãƒ è‰²
    if r > 220 and g > 210 and b > 170 and v > 130:
        logging.debug("ã‚¯ãƒªãƒ¼ãƒ è‰²æ¤œå‡ºï¼ˆåºƒã‚ï¼‰")
        return True

    # ãƒ‘ã‚¹ãƒ†ãƒ«ãƒ‘ãƒ¼ãƒ—ãƒ«
    if (r > 220 and g > 210 and b > 240 and abs(r - b) < 60 and v > 130) or \
       (220 <= h <= 300 and s < 50 and v > 130):  # #F6DAF6, #E9DAF9 å¯¾å¿œ
        logging.debug("ãƒ‘ã‚¹ãƒ†ãƒ«ãƒ‘ãƒ¼ãƒ—ãƒ«æ¤œå‡ºï¼ˆæ˜ã‚‹ã•OKï¼‰")
        return True

    # ç™½ç°ãƒ”ãƒ³ã‚¯ç³»
    if r > 200 and g > 180 and b > 200 and v > 130:
        logging.debug("ãµã‚ã‚‚ã“ç™½ç°ãƒ”ãƒ³ã‚¯æ¤œå‡ºï¼ˆæ¡ƒèŠ±å¯¾å¿œï¼‰")
        return True

    # ç™½ç°ç³»
    if 200 <= r <= 255 and 200 <= g <= 240 and 200 <= b <= 255 and abs(r - g) < 30 and abs(r - b) < 30 and v > 130:
        logging.debug("ç™½ç°ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼ï¼ˆæŸ”ã‚‰ã‹ç³»ï¼‰")
        return True

    if 200 <= h <= 300 and s < 80 and v > 130:
        logging.debug("ãƒ‘ã‚¹ãƒ†ãƒ«ç³»ç´«ï½ãƒ”ãƒ³ã‚¯æ¤œå‡ºï¼ˆæ˜ã‚‹ã•OKï¼‰")
        return True

    if 190 <= h <= 260 and s < 100 and v > 130:
        logging.debug("å¤œç©ºãƒ‘ã‚¹ãƒ†ãƒ«ç´«æ¤œå‡ºï¼ˆåºƒã‚ã€æ˜ã‚‹ã•OKï¼‰")
        return True

    return False

def clean_output(text):
    text = re.sub(r'[\r\n]+', ' ', text)
    text = re.sub(r'\s{2,}', ' ', text)
    text = re.sub(r'^(çŸ­ãã€ãµã‚ã‚‚ã“ãªè¿”äº‹ã‚’ã—ã¦ã­ã€‚|.*â†’\s*|å¯’ã„ã€œ\s*)', '', text)
    text = re.sub(r'^.*?((ã‚‚ãµ|ãµã‚)[^ã€‚]*)$', r'\1', text, flags=re.DOTALL)
    text = re.sub(r'^ã‚‚ãµã‚‚ãµã§ã‚ã£ãŸã¾ã‚ã€œâ™¡\s*', '', text)  # ãƒ†ãƒ³ãƒ—ãƒ¬å‰Šé™¤
    text = re.sub(r'^[^ã€‚ï¼ï¼Ÿ\n]{1,10}ã£ã¦ç™’ã•ã‚Œã‚‹ã‚ˆã­ã€œ\s*', '', text)  # ãƒ†ãƒ³ãƒ—ãƒ¬å‰Šé™¤
    text = re.sub(r'[^\w\sã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯ã€‚ã€ï¼ï¼Ÿ!?â™¡ï¼ˆï¼‰ã€Œã€â™ªã€œãƒ¼â€¦wç¬‘]+', '', text)
    text = re.sub(r'([ã€‚ã€ï¼ï¼Ÿ])\s*ğŸ’–', r'\1ğŸ’–', text)
    text = re.sub(r'[ã€‚ã€ï¼ï¼Ÿ]{2,}', lambda m: m.group(0)[0], text)
    return text.strip()

def open_calm_reply(image_url, text="", context="ãµã‚ã‚‚ã“å…±æ„Ÿ", lang="ja"):
    NG_WORDS = globals()["EMOTION_TAGS"].get("nsfw_ng", [])
    NG_PHRASES = [
        r"(?:æŠ•ç¨¿|ãƒ¦ãƒ¼ã‚¶ãƒ¼|ä¾‹æ–‡|ãƒã‚¹ã‚¯ãƒƒãƒˆ|ãƒã‚¹ã‚±ãƒƒãƒˆ|ãƒ•ã‚©ãƒ¼ãƒ©ãƒ |è¿”äº‹|ä¼šè©±|å…±æ„Ÿ)",
        r"(?:ç™’ã—ç³»ã®ãµã‚ã‚‚ã“ãƒã‚¹ã‚³ãƒƒãƒˆ|æŠ•ç¨¿å†…å®¹ã«å¯¾ã—ã¦)",
        r"[â– #]{2,}",
        r"!{5,}", r"\?{5,}", r"[!ï¼Ÿ]{5,}",
        r"(?:(ãµã‚|ã‚‚ã“|ã‚‚ã¡|ã½ã“)\1{3,})",
        r"[â™ª~]{2,}",
        r"(#\w+){3,}",
        r"^[^\w\s]+$", r"(\w+\s*,){3,}", r"[\*:\.]{2,}"
    ]
    SEASONAL_WORDS_BLACKLIST = ["å¯’ã„", "ã‚ã£ãŸã¾ã‚", "å‡ãˆã‚‹", "å†·ãŸã„"]

    templates = deepcopy(ORIGINAL_TEMPLATES)
    if not check_template_integrity(templates):
        templates = auto_revert_templates(templates)
    audit_templates_changes(ORIGINAL_TEMPLATES, templates)

    NORMAL_TEMPLATES_JP = templates["NORMAL_TEMPLATES_JP"]
    SHONBORI_TEMPLATES_JP = templates["SHONBORI_TEMPLATES_JP"]
    MOGUMOGU_TEMPLATES_JP = templates["MOGUMOGU_TEMPLATES_JP"]
    NORMAL_TEMPLATES_EN = templates["NORMAL_TEMPLATES_EN"]
    MOGUMOGU_TEMPLATES_EN = templates["MOGUMOGU_TEMPLATES_EN"]
    COSMETICS_TEMPLATES_JP = templates["COSMETICS_TEMPLATES_JP"]
    COSMETICS_TEMPLATES_EN = templates["COSMETICS_TEMPLATES_EN"]
    CHARACTER_TEMPLATES_JP = templates["CHARACTER_TEMPLATES_JP"]
    CHARACTER_TEMPLATES_EN = templates["CHARACTER_TEMPLATES_EN"]

    detected_tags = []
    for tag, words in globals()["EMOTION_TAGS"].items():
        if any(word in text.lower() for word in words):
            detected_tags.append(tag)

    if "food_ng" in detected_tags or any(word.lower() in text.lower() for word in NG_WORDS):
        logging.debug(f"ğŸ½ï¸ NGãƒ¯ãƒ¼ãƒ‰/é£Ÿäº‹æ¤œå‡º: {text[:40]}")
        return random.choice(MOGUMOGU_TEMPLATES_JP) if lang == "ja" else random.choice(MOGUMOGU_TEMPLATES_EN)
    elif "shonbori" in detected_tags:
        return random.choice(SHONBORI_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)
    elif "safe_cosmetics" in detected_tags:
        if lang == "ja":
            for cosmetic, templates in COSMETICS_TEMPLATES_JP.items():
                if cosmetic in text.lower():
                    return random.choice(templates)
        else:
            for cosmetic, templates in COSMETICS_TEMPLATES_EN.items():
                if any(word in text.lower() for word in globals()["EMOTION_TAGS"]["safe_cosmetics"]):
                    return random.choice(templates)
    elif any(tag in detected_tags for tag in globals()["SAFE_CHARACTER"]):
        if lang == "ja":
            for char_type, templates in CHARACTER_TEMPLATES_JP.items():
                if any(word in text.lower() for word in globals()["SAFE_CHARACTER"][char_type]):
                    return random.choice(templates)
        else:
            for char_type, templates in CHARACTER_TEMPLATES_EN.items():
                if any(word in text.lower() for word in globals()["SAFE_CHARACTER"][char_type]):
                    return random.choice(templates)
    elif any(word in text.lower() for word in globals()["GENERAL_TAGS"]):
        return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

    # å˜èªå…¥åŠ›å¯¾å¿œ
    if len(text.strip()) <= 4:
        suffixes = [
            "ã£ã¦ç™’ã•ã‚Œã‚‹ã‚ˆã­ã€œ",
            "ã£ã¦ã‚‚ãµã‚‚ãµã—ã¦ã¦å¥½ãã€œ",
            "ã£ã¦ãµã‚ãµã‚ã§è½ã¡ç€ãã€œ",
            "ã£ã¦è¦‹ã¦ã‚‹ã ã‘ã§å¹¸ã›ã€œ",
        ]
        text = f"{text.strip()}{random.choice(suffixes)}"

    examples = [
        ("å¯’ã„ã€œ", "ã‚‚ãµã‚‚ãµã§ã‚ã£ãŸã¾ã‚ã€œâ™¡"),
        ("æ¯›å¸ƒ", "æ¯›å¸ƒã«ãã‚‹ã¾ã£ã¦ã¬ãã¬ãã ã­ã€œğŸ°"),
        ("çŒ«", "çŒ«ã£ã¦ç™’ã—ã®ã‹ãŸã¾ã‚Šã ã‚ˆã­ã€œğŸ¾"),
        ("ã¬ã„ãã‚‹ã¿", "ãã‚…ã£ã¦ã—ãŸããªã‚‹ã­ã€œğŸ’•"),
        ("é›²", "ã‚‚ãã‚‚ãã—ã¦ã¦å¯æ„›ã„ã‚ˆã­ã€œâ˜ï¸"),
    ]
    prompt = (
        "ãµã‚ãµã‚ã§ã‚„ã•ã—ã„è¿”äº‹ã‚’è€ƒãˆã¦ã­ã€‚\n"
        "â€»ã€ã‚‚ãµã‚‚ãµã§ã‚ã£ãŸã¾ã‚ã€œâ™¡ã€ã‚„ã€ç™’ã•ã‚Œã‚‹ã‚ˆã­ã€œã€ã¯æ¯å›å…¥ã‚Œãªãã¦ã„ã„ã‚ˆã€‚\n"
        + "\n".join([f"{q} â†’ {a}" for q, a in examples])
        + f"\n{text.strip()} â†’"
    )
    logging.debug(f"ğŸ§ª ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç¢ºèª: {prompt}")

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=150).to(model.device)
    try:
        outputs = model.generate(
            **inputs,
            max_new_tokens=25,  # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’æ¸›ã‚‰ã™
            pad_token_id=tokenizer.pad_token_id,
            do_sample=True,
            temperature=0.6,
            top_k=30,
            top_p=0.9,
            no_repeat_ngram_size=3
        )
        raw_reply = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
        logging.debug(f"ğŸ§¸ Raw AIå‡ºåŠ›ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰: {raw_reply}")
        logging.debug(f"ğŸ§¸ AIå‡ºåŠ›ï¼ˆã‚¯ãƒªãƒ¼ãƒ³å¾Œï¼‰: {clean_output(raw_reply)}")

        reply = clean_output(raw_reply)
        reply = apply_fuwamoko_tone(reply)

        if not reply or len(reply) < 5:
            logging.warning(f"â­ï¸ SKIP: ç©ºã¾ãŸã¯çŸ­ã™ã: len={len(reply)}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: ç”Ÿæˆå¤±æ•—")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        if not re.search(r'(ã§ã™|ã¾ã™|ã­|ã‚ˆ|ã |ã‚‹|ãŸ|ã«|ã‚’|ãŒ|ã¯)', reply) or re.fullmatch(r'[ã-ã‚“ãƒ¼ã‚›ã‚œã€‚ã€\sã€Œã€ï¼ï¼Ÿ]+', reply):
            logging.warning(f"â­ï¸ SKIP: æ–‡ç« ä¸æˆç«‹: ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: æ–‡æ³•ä¸ååˆ†ã¾ãŸã¯æ“¬éŸ³èªã®ã¿")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        if len(reply) < 10 or len(reply) > 70:
            logging.warning(f"â­ï¸ SKIP: é•·ã•ä¸é©åˆ‡: len={len(reply)}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: é•·ã•è¶…é/ä¸è¶³")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        for bad in NG_PHRASES:
            if re.search(bad, reply):
                logging.warning(f"â­ï¸ SKIP: NGãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œå‡º: {bad}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: NGãƒ•ãƒ¬ãƒ¼ã‚º")
                return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        if any(word in reply for word in SEASONAL_WORDS_BLACKLIST):
            logging.warning("â­ï¸ SKIP: å­£ç¯€ä¸ä¸€è‡´: å¯’ã•è¡¨ç¾ã‚ã‚Š")
            return random.choice(NORMAL_TEMPLATES_JP)

        if reply.count("ã‚‚ãµã‚‚ãµ") > 1:
            reply = reply.replace("ã‚‚ãµã‚‚ãµ", "ãµã‚ãµã‚", 1)

        if not re.search(r"[ğŸŒ¸ğŸ’•ğŸ¾â˜ï¸ğŸ°âœ¨â™¡]", reply):
            reply += " " + random.choice(["ğŸ°", "ğŸŒ¸", "ğŸ’•"])

        logging.info(f"ğŸ¦Š AIç”ŸæˆæˆåŠŸ: {reply}, é•·ã•: {len(reply)}")
        return reply
    except Exception as e:
        logging.error(f"âŒ AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

def extract_valid_cid(ref):
    try:
        cid_candidate = str(ref.link) if hasattr(ref, 'link') else str(ref)
        if re.match(r'^baf[a-z0-9]{40,60}$', cid_candidate):
            return cid_candidate
        logging.error(f"âŒ ç„¡åŠ¹ãªCID: {cid_candidate}")
        return None
    except Exception as e:
        logging.error(f"âŒ CIDæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return None

def check_skin_ratio(img_pil_obj):
    try:
        if img_pil_obj is None:
            logging.debug("ç”»åƒãƒ‡ãƒ¼ã‚¿ç„¡åŠ¹ (PIL Imageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒNone)")
            return 0.0

        img_pil_obj = img_pil_obj.convert("RGB")
        img_np = cv2.cvtColor(np.array(img_pil_obj), cv2.COLOR_RGB2BGR)
        if img_np is None or img_np.size == 0:
            logging.error("âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ç„¡åŠ¹")
            return 0.0

        hsv_img = cv2.cvtColor(img_np, cv2.COLOR_BGR2HSV)
        lower = np.array([5, 50, 70], dtype=np.uint8)
        upper = np.array([20, 150, 240], dtype=np.uint8)
        mask = cv2.inRange(hsv_img, lower, upper)
        skin_colors = img_np[mask > 0]

        if skin_colors.size > 0:
            avg_color = np.mean(skin_colors, axis=0)
            logging.debug(f"å¹³å‡è‚Œè‰²: BGR={avg_color}")
            if np.mean(avg_color) > 220:
                logging.debug("â†’ æ˜ã‚‹ã™ãã‚‹ã®ã§è‚Œè‰²ã§ã¯ãªãç™½ã¨ã¿ãªã™")
                return 0.0

        skin_area = np.sum(mask > 0)
        total_area = img_np.shape[0] * img_np.shape[1]
        skin_ratio = skin_area / total_area if total_area > 0 else 0.0
        logging.debug(f"è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}")
        return skin_ratio
    except Exception as e:
        logging.error(f"âŒ è‚Œè‰²è§£æã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return 0.0

def is_mutual_follow(client, handle):
    try:
        their_followers = {f.handle for f in client.get_followers(actor=handle, limit=100).followers}
        my_followers = {f.handle for f in client.get_followers(actor=HANDLE, limit=100).followers}
        return handle in my_followers and HANDLE in their_followers
    except Exception as e:
        logging.error(f"âŒ ç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼åˆ¤å®šã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def download_image_from_blob(cid, client, did=None):
    if not cid or not re.match(r'^baf[a-z0-9]{40,60}$', cid):
        logging.error(f"âŒ ç„¡åŠ¹ãªCID: {cid}")
        return None

    if client and did:
        try:
            blob = client.get_blob(cid=cid, did=did)
            img_data = BytesIO(blob.data)
            img = Image.open(img_data)
            img.load()
            logging.info(f"ğŸŸ¢ Blobç”»åƒå½¢å¼={img.format}, ã‚µã‚¤ã‚º={img.size}")
            return img
        except Exception as e:
            logging.error(f"âŒ Blob APIã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

    did_safe = unquote(did) if did else None
    cdn_urls = [
        f"https://cdn.bsky.app/img/feed_thumbnail/plain/{quote(did_safe)}/{quote(cid)}@jpeg" if did_safe else None,
        f"https://cdn.bsky.app/img/feed_fullsize/plain/{quote(did_safe)}/{quote(cid)}@jpeg" if did_safe else None
    ]
    headers = {"User-Agent": "Mozilla/5.0"}

    for url in [u for u in cdn_urls if u]:
        try:
            response = requests.get(url, headers=headers, timeout=10, stream=True)
            response.raise_for_status()
            img_data = BytesIO(response.content)
            img = Image.open(img_data)
            img.load()
            logging.info(f"ğŸŸ¢ ç”»åƒå½¢å¼={img.format}, ã‚µã‚¤ã‚º={img.size}")
            return img
        except Exception as e:
            logging.error(f"âŒ CDNå–å¾—å¤±æ•—: {type(e).__name__}: {e}, url={url}")
            continue

    logging.error("âŒ ç”»åƒå–å¾—å¤±æ•—")
    return None

def process_image(image_data, text="", client=None, post=None):
    if not hasattr(image_data, 'image') or not hasattr(image_data.image, 'ref'):
        logging.debug("ç”»åƒãƒ‡ãƒ¼ã‚¿æ§‹é€ ç•°å¸¸")
        return False

    cid = extract_valid_cid(image_data.image.ref)
    if not cid:
        return False

    try:
        author_did = post.post.author.did if post and hasattr(post, 'post') else None
        img = download_image_from_blob(cid, client, did=author_did)
        if img is None:
            logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒå–å¾—å¤±æ•—ï¼ˆãƒ­ã‚°ã¯ä¸Šè¨˜ï¼‰")
            return False

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã«è¿½åŠ ï¼‰
fuwamoko_model = torch.jit.load("fuwamoko_model.pt").to("cuda")  # GitHub Actionsç”¨ã«CPUã§

def process_image(image_data, text="", client=None, post=None):
    if not hasattr(image_data, 'image') or not hasattr(image_data.image, 'ref'):
        logging.debug("ç”»åƒãƒ‡ãƒ¼ã‚¿æ§‹é€ ç•°å¸¸")
        return False

    cid = extract_valid_cid(image_data.image.ref)
    if not cid:
        return False

    try:
        author_did = post.post.author.did if post and hasattr(post, 'post') else None
        img = download_image_from_blob(cid, client, did=author_did)
        if img is None:
            logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒå–å¾—å¤±æ•—ï¼ˆãƒ­ã‚°ã¯ä¸Šè¨˜ï¼‰")
            return False

        # PyTorchç”¨ã«ãƒªã‚µã‚¤ã‚ºã¨å‰å‡¦ç†
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        img_tensor = transform(img).unsqueeze(0).to("cuda")

        # æ¨è«–
        with torch.no_grad():
            output = fuwamoko_model(img_tensor)
            _, predicted = torch.max(output, 1)
            category = ["other", "food", "fuwamoko"][predicted.item()]
            logging.debug(f"ğŸ§ª PyTorchæ¨è«–çµæœ: {category}")

        # è‰²æ¤œçŸ¥ã‚‚ä½µç”¨ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
        resized_img = img.resize((64, 64))
        hsv_img = cv2.cvtColor(np.array(resized_img), cv2.COLOR_RGB2HSV)
        bright_colors = [(r, g, b) for (r, g, b), (_, s, v) in zip(resized_img.getdata(), hsv_img.reshape(-1, 3)) if v > 130]
        color_counts = Counter(bright_colors)
        top_colors = color_counts.most_common(5)
        logging.debug(f"ãƒˆãƒƒãƒ—5ã‚«ãƒ©ãƒ¼ï¼ˆæ˜åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œï¼‰: {[(c[0], c[1]) for c in top_colors]}")

        fluffy_count = 0
        bright_color_count = 0
        food_color_count = 0
        for color, _ in top_colors:
            r, g, b = color
            if is_fluffy_color(r, g, b, bright_colors):
                fluffy_count += 1
            if r > 180 and g > 180 and b > 180:
                bright_color_count += 1
            if ((150 <= r <= 200 and 150 <= g <= 200 and 150 <= b <= 200) or  # ãƒãƒ /åµ
                (220 <= r <= 250 and 220 <= g <= 250 and 210 <= b <= 230) or  # ãŠã«ãã‚Š
                (230 <= r <= 255 and 200 <= g <= 230 and 130 <= b <= 160) or  # è±†è…
                (r == 255 and g == 255 and b == 255)):                       # ç´”ç™½
                food_color_count += 1
        logging.debug(f"ãµã‚ã‚‚ã“è‰²ã‚«ã‚¦ãƒ³ãƒˆ: {fluffy_count}, æ˜ã‚‹ã„è‰²æ•°: {bright_color_count}, é£Ÿå“è‰²æ•°: {food_color_count}")

        skin_ratio = check_skin_ratio(img)
        food_ratio = food_color_count / 5 if top_colors else 0.0
        logging.debug(f"è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}, é£Ÿå“è‰²æ¯”ç‡: {food_ratio:.2%}, ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼æ•°: {fluffy_count}")

        # æœ€çµ‚åˆ¤å®š
        if category == "fuwamoko" or (fluffy_count >= 2 and food_ratio <= 0.2 and skin_ratio < 0.5):
            logging.info("ğŸŸ¢ ãµã‚ã‚‚ã“è‰²æ¤œå‡ºã¾ãŸã¯PyTorchåˆ¤å®šæˆåŠŸ")
            return True
        elif category == "food" or food_ratio > 0.2:
            logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: é£Ÿå“è‰²æ¯”ç‡ {food_ratio:.2%} > 20% ã¾ãŸã¯ PyTorchåˆ¤å®š")
            return False
        else:
            logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è‰²æ¡ä»¶ä¸è¶³ã¾ãŸã¯PyTorchåˆ¤å®š")
            return False

        check_text = text.lower()
        try:
            if any(word in check_text for word in globals()["HIGH_RISK_WORDS"]):
                if skin_ratio < 0.4 and fluffy_count >= 2:
                    logging.info("ğŸŸ¢ é«˜ãƒªã‚¹ã‚¯ã ãŒæ¡ä»¶OK")
                    return True
                else:
                    logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: é«˜ãƒªã‚¹ã‚¯ï¼‹æ¡ä»¶NG")
                    return False
            if any(word in check_text for word in globals()["EMOTION_TAGS"]["nsfw_ng"]):
                logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: NSFWé–¢é€£æ¤œå‡º")
                return False
        except KeyError as e:
            logging.error(f"âŒ ã‚°ãƒ­ãƒ¼ãƒãƒ«è¾æ›¸ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            return False

    except Exception as e:
        logging.error(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (cid={cid}, uri={getattr(post, 'uri', 'unknown')})")
        return False
        
def is_quoted_repost(post):
    try:
        actual_post = post.post if hasattr(post, 'post') else post
        record = getattr(actual_post, 'record', None)
        if record and hasattr(record, 'embed') and record.embed:
            embed = record.embed
            logging.debug(f"å¼•ç”¨ãƒªãƒã‚¹ãƒˆãƒã‚§ãƒƒã‚¯: {embed}")
            if hasattr(embed, 'record') and embed.record:
                logging.debug("å¼•ç”¨ãƒªãƒã‚¹ãƒˆæ¤œå‡ºï¼ˆrecordï¼‰")
                return True
            elif hasattr(embed, 'record') and hasattr(embed.record, 'record') and embed.record.record:
                logging.debug("å¼•ç”¨ãƒªãƒã‚¹ãƒˆæ¤œå‡ºï¼ˆrecordWithMediaï¼‰")
                return True
        return False
    except Exception as e:
        logging.error(f"âŒ å¼•ç”¨ãƒªãƒã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def load_reposted_uris():
    REPOSTED_FILE = "reposted_uris.txt"
    if os.path.exists(REPOSTED_FILE):
        try:
            with open(REPOSTED_FILE, 'r', encoding='utf-8') as f:
                uris = set(line.strip() for line in f if line.strip())
                logging.info(f"ğŸŸ¢ å†æŠ•ç¨¿URIèª­ã¿è¾¼ã¿: {len(uris)}ä»¶")
                return uris
        except Exception as e:
            logging.error(f"âŒ å†æŠ•ç¨¿URIèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            return set()
    return set()

def detect_language(client, handle):
    try:
        profile = client.get_profile(actor=handle)
        bio = profile.display_name.lower() + " " + getattr(profile, "description", "").lower()
        if any(kw in bio for kw in ["æ—¥æœ¬èª", "æ—¥æœ¬", "ã«ã»ã‚“", "japanese", "jp"]):
            return "ja"
        elif any(kw in bio for kw in ["english", "us", "uk", "en"]):
            return "en"
        return "ja"
    except Exception as e:
        logging.error(f"âŒ è¨€èªåˆ¤å®šã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return "ja"

def is_priority_post(text):
    return "@mirinchuuu" in text.lower()

def is_reply_to_self(post):
    reply = getattr(post.record, "reply", None) if hasattr(post, 'record') else None
    if reply and hasattr(reply, 'parent') and hasattr(reply.parent, 'uri'):
        return reply.parent.uri == post.post.uri
    return False

fuwamoko_uris = {}

def normalize_uri(uri):
    try:
        if not uri.startswith('at://'):
            uri = f"at://{uri.lstrip('/')}"
        parts = uri.split('/')
        if len(parts) >= 5:
            normalized = f"at://{parts[2]}/{parts[3]}/{parts[4]}"
            logging.debug(f"ğŸ¦Š URIæ­£è¦åŒ–: {uri} -> {normalized}")
            return normalized
        logging.warning(f"â­ï¸ URIæ­£è¦åŒ–å¤±æ•—: ä¸æ­£ãªå½¢å¼: {uri}")
        return uri
    except Exception as e:
        logging.error(f"âŒ URIæ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return uri

def validate_fuwamoko_file():
    if not os.path.exists(FUWAMOKO_FILE):
        logging.info("ğŸŸ¢ ãµã‚ã‚‚ã“å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        with open(FUWAMOKO_FILE, 'w', encoding='utf-8') as f:
            f.write("")
        return True
    try:
        with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for line in lines:
                clean_line = line.strip()
                if not clean_line:
                    continue
                if not re.match(r'^at://[^|]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}(?:\d{3})?\+\d{2}:\d{2}$', clean_line):
                    logging.error(f"âŒ ç„¡åŠ¹ãªå±¥æ­´è¡Œ: {repr(clean_line)}")
                    return False
        return True
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def repair_fuwamoko_file():
    temp_file = FUWAMOKO_FILE + ".tmp"
    valid_lines = []
    if os.path.exists(FUWAMOKO_FILE):
        try:
            with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    clean_line = line.strip()
                    if not clean_line:
                        continue
                    if re.match(r'^at://[^|]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}(?:\d{3})?\+\d{2}:\d{2}$', clean_line):
                        valid_lines.append(line)
                    else:
                        logging.warning(f"â­ï¸ ç ´æè¡Œã‚¹ã‚­ãƒƒãƒ—: {repr(clean_line)}")
            with open(temp_file, 'w', encoding='utf-8') as f:
                f.writelines(valid_lines)
            os.replace(temp_file, FUWAMOKO_FILE)
            logging.info(f"ğŸŸ¢ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©å®Œäº†: {len(valid_lines)}ä»¶ä¿æŒ")
        except Exception as e:
            logging.error(f"âŒ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            if os.path.exists(temp_file):
                os.remove(temp_file)
    else:
        with open(FUWAMOKO_FILE, 'w', encoding='utf-8') as f:
            f.write("")
        logging.info("ğŸŸ¢ æ–°è¦å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")

def load_fuwamoko_uris():
    global fuwamoko_uris
    fuwamoko_uris.clear()
    if not validate_fuwamoko_file():
        logging.warning("âš ï¸ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ç ´æã€‚ä¿®å¾©ã‚’è©¦ã¿ã¾ã™ã€‚")
        repair_fuwamoko_file()
    try:
        with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
            logging.info(f"ğŸŸ¢ ãµã‚ã‚‚ã“å±¥æ­´ã‚µã‚¤ã‚º: {len(content)} bytes")
            if content.strip():
                for line in content.splitlines():
                    if line.strip():
                        try:
                            uri, timestamp = line.strip().split("|", 1)
                            normalized_uri = normalize_uri(uri)
                            fuwamoko_uris[normalized_uri] = datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
                            logging.debug(f"ğŸ¦Š å±¥æ­´èª­ã¿è¾¼ã¿: {normalized_uri}")
                        except ValueError as e:
                            logging.warning(f"â­ï¸ ç ´æè¡Œã‚¹ã‚­ãƒƒãƒ—: {repr(line.strip())}: {e}")
                            continue
            logging.info(f"ğŸŸ¢ ãµã‚ã‚‚ã“URIèª­ã¿è¾¼ã¿: {len(fuwamoko_uris)}ä»¶")
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        fuwamoko_uris.clear()

def save_fuwamoko_uri(uri, indexed_at):
    global fuwamoko_uris
    normalized_uri = normalize_uri(uri)
    lock = filelock.FileLock(FUWAMOKO_LOCK, timeout=5.0)
    try:
        with lock:
            logging.debug(f"ğŸ¦Š ãƒ­ãƒƒã‚¯å–å¾—: {FUWAMOKO_LOCK}")
            if normalized_uri in fuwamoko_uris and (datetime.now(timezone.utc) - fuwamoko_uris[normalized_uri]).total_seconds() < 24 * 3600:
                logging.debug(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: 24æ™‚é–“ä»¥å†…: {normalized_uri}")
                return
            if isinstance(indexed_at, str):
                indexed_at = datetime.fromisoformat(indexed_at.replace("Z", "+00:00"))
            with open(FUWAMOKO_FILE, 'a', encoding='utf-8') as f:
                f.write(f"{normalized_uri}|{indexed_at.isoformat()}\n")
            fuwamoko_uris[normalized_uri] = indexed_at
            logging.info(f"ğŸŸ¢ å±¥æ­´ä¿å­˜: {normalized_uri}")
            with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                last_line = lines[-1].strip() if lines else ""
                if last_line.startswith(normalized_uri):
                    logging.debug(f"ğŸ¦Š å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: æœ€å¾Œã®è¡Œ={last_line}")
                else:
                    logging.error(f"âŒ å±¥æ­´ä¿å­˜å¤±æ•—: æœ€å¾Œã®è¡Œ={last_line}")
            load_fuwamoko_uris()
    except filelock.Timeout:
        logging.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {FUWAMOKO_LOCK}")
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def load_session_string():
    try:
        if os.path.exists(SESSION_FILE):
            with open(SESSION_FILE, 'r', encoding='utf-8') as f:
                return f.read().strip()
        return None
    except Exception as e:
        logging.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return None

def save_session_string(session_str):
    try:
        with open(SESSION_FILE, 'w', encoding='utf-8') as f:
            f.write(session_str)
    except Exception as e:
        logging.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def has_image(post):
    try:
        actual_post = post.post if hasattr(post, 'post') else post
        if not hasattr(actual_post, 'record') or not hasattr(actual_post.record, 'embed'):
            return False
        embed = actual_post.record.embed
        return (
            (hasattr(embed, 'images') and embed.images) or
            (hasattr(embed, 'record') and hasattr(embed.record, 'embed') and hasattr(embed.record.embed, 'images') and embed.record.embed.images) or
            (getattr(embed, '$type', '') == 'app.bsky.embed.recordWithMedia' and hasattr(embed, 'media') and hasattr(embed.media, 'images') and embed.media.images)
        )
    except Exception as e:
        logging.error(f"âŒ ç”»åƒãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False
        
def classify_text_emotion(text):
    text = text.lower()
    # NGç³»æœ€å„ªå…ˆ
    for tag in ["nsfw_ng", "food_ng"]:
        for word in globals()["EMOTION_TAGS"].get(tag, []):
            if word in text:
                logging.debug(f"âš ï¸ '{word}' æ¤œå‡º â†’ NGã‚¿ã‚°: {tag}")
                return tag
    # ä¸­é–“ã‚±ãƒ¼ã‚¹ï¼ˆé«ªã‚„ã‚ªãƒ¼ãƒ©ï¼‰
    if any(word in text for word in ["é«ªã®æ¯›", "ã‚ªãƒ¼ãƒ©", "ãƒˆãƒ¼ã‚¯", "è£œæ­£"]):
        logging.debug("â–³ ä¸­é–“ã‚±ãƒ¼ã‚¹æ¤œå‡º: é«ª/ã‚ªãƒ¼ãƒ©/ãƒˆãƒ¼ã‚¯é–¢é€£")
        return "neutral_ambiguous"  # ä¸­é–“åˆ¤å®š
    # é€šå¸¸ã‚¿ã‚°
    for tag, words in globals()["EMOTION_TAGS"].items():
        if tag.endswith("_ng") or tag == "neutral_ambiguous":
            continue
        for word in words:
            if word in text:
                logging.debug(f"âœ… '{word}' æ¤œå‡º â†’ ã‚¿ã‚°: {tag}")
                return tag
    return "neutral"
    
def is_suspicious_context(text, bio=""):
    suspicious_keywords = [
        "#ã‚°ãƒ©ãƒ“ã‚¢ã‚¢ã‚¤ãƒ‰ãƒ«", "#ãƒ¡ãƒ³ã‚ºã‚¨ã‚¹ãƒ†", "#åå¤å±‹ãƒ¡ãƒ³ã‚¨ã‚¹", "#é¢¨ä¿—", "#ã”äºˆç´„", "#DMã§",
        "ãƒã‚·ãƒ¥ãƒãƒ­", "æ€§æ„Ÿ", "ä½“", "è°·é–“", "èƒ¸å…ƒ", "ãƒ©ãƒ³ã‚¸ã‚§ãƒªãƒ¼", "ãƒªãƒ”æ§˜", "ãƒªãƒ³ã‚¯"
    ]
    text = text.lower()
    bio = bio.lower()
    return any(kw in text or kw in bio for kw in suspicious_keywords)

def process_post(post_data, client, fuwamoko_uris, reposted_uris):
    try:
        actual_post = post_data.post if hasattr(post_data, 'post') else post_data
        uri = str(actual_post.uri)
        post_id = uri.split('/')[-1]
        text = getattr(actual_post.record, 'text', '') if hasattr(actual_post.record, 'text') else ''
        bio = getattr(client.get_profile(actor=actual_post.author.handle), 'description', '')

        # æ–‡è„ˆãƒã‚§ãƒƒã‚¯
        if is_suspicious_context(text, bio):
            logging.info(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ç–‘ã‚ã—ã„æ–‡è„ˆæ¤œå‡º: {text[:40]} ({post_id})")
            save_fuwamoko_uri(uri, actual_post.indexed_at)
            return False

        emotion = classify_text_emotion(text)
        if emotion.endswith("_ng") or emotion == "neutral_ambiguous":
            logging.info(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: NGã¾ãŸã¯ä¸­é–“åˆ¤å®šï¼ˆ{emotion}ï¼‰: {text[:40]} ({post_id})")
            save_fuwamoko_uri(uri, actual_post.indexed_at)
            return False

        is_reply = hasattr(actual_post.record, 'reply') and actual_post.record.reply is not None
        if is_reply and not (is_priority_post(text) or is_reply_to_self(post_data)):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãƒªãƒ—ãƒ©ã‚¤ï¼ˆé@mirinchuuu/éè‡ªå·±ï¼‰: {text[:20]} ({post_id})")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒªãƒ—ãƒ©ã‚¤: {post_id}")
            return False

        print(f"ğŸ¦Š POSTå‡¦ç†é–‹å§‹: @{actual_post.author.handle} ({post_id})")
        logging.info(f"ğŸŸ¢ POSTå‡¦ç†é–‹å§‹: @{actual_post.author.handle} ({post_id})")
        normalized_uri = normalize_uri(uri)
        if normalized_uri in fuwamoko_uris:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: æ—¢å­˜æŠ•ç¨¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: æ—¢å­˜æŠ•ç¨¿: {post_id}")
            return False
        if actual_post.author.handle == HANDLE:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è‡ªåˆ†ã®æŠ•ç¨¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: è‡ªåˆ†ã®æŠ•ç¨¿: {post_id}")
            return False
        if is_quoted_repost(post_data):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: å¼•ç”¨ãƒªãƒã‚¹ãƒˆ: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: å¼•ç”¨ãƒªãƒã‚¹ãƒˆ: {post_id}")
            return False
        if post_id in reposted_uris:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: å†æŠ•ç¨¿æ¸ˆã¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: å†æŠ•ç¨¿æ¸ˆã¿: {post_id}")
            return False

        author = actual_post.author.handle
        indexed_at = actual_post.indexed_at

        if not has_image(post_data):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒãªã—: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒãªã—: {post_id}")
            return False

        image_data_list = []
        embed = getattr(actual_post.record, 'embed', None)
        if embed:
            if hasattr(embed, 'images') and embed.images:
                image_data_list.extend(embed.images)
            elif hasattr(embed, 'record') and hasattr(embed.record, 'embed') and hasattr(embed.record.embed, 'images'):
                image_data_list.extend(embed.record.embed.images)
            elif getattr(embed, '$type', '') == 'app.bsky.embed.recordWithMedia' and hasattr(embed, 'media') and hasattr(embed.media, 'images'):
                image_data_list.extend(embed.media.images)

        if not is_mutual_follow(client, author):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: éç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼: @{author} ({post_id})")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: éç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼: @{author} ({post_id})")
            return False

        for i, image_data in enumerate(image_data_list):
            try:
                print(f"ğŸ¦Š ç”»åƒå‡¦ç†é–‹å§‹: {i+1}/{len(image_data_list)} ({post_id})")
                logging.debug(f"ç”»åƒå‡¦ç†é–‹å§‹: {i+1}/{len(image_data_list)} ({post_id})")
                if process_image(image_data, text, client=client, post=post_data):
                    if random.random() > 0.5:
                        print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆ50%ï¼‰: {post_id}")
                        logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒ©ãƒ³ãƒ€ãƒ : {post_id}")
                        save_fuwamoko_uri(uri, indexed_at)
                        return False
                    lang = detect_language(client, author)
                    reply_text = open_calm_reply("", text, lang=lang)
                    if not reply_text:
                        print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è¿”ä¿¡ç”Ÿæˆå¤±æ•—: {post_id}")
                        logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: è¿”ä¿¡ç”Ÿæˆå¤±æ•—: {post_id}")
                        save_fuwamoko_uri(uri, indexed_at)
                        return False
                    root_ref = models.ComAtprotoRepoStrongRef.Main(
                        uri=uri,
                        cid=actual_post.cid
                    )
                    parent_ref = models.ComAtprotoRepoStrongRef.Main(
                        uri=uri,
                        cid=actual_post.cid
                    )
                    reply_ref = models.AppBskyFeedPost.ReplyRef(
                        root=root_ref,
                        parent=parent_ref
                    )
                    print(f"ğŸ¦Š è¿”ä¿¡é€ä¿¡: @{author}: {reply_text} ({post_id})")
                    logging.debug(f"è¿”ä¿¡é€ä¿¡: @{author}: {reply_text} ({post_id})")
                    client.send_post(text=reply_text, reply_to=reply_ref)
                    save_fuwamoko_uri(uri, indexed_at)
                    print(f"âœ… SUCCESS: è¿”ä¿¡æˆåŠŸ: @{author} ({post_id})")
                    logging.info(f"ğŸŸ¢ è¿”ä¿¡æˆåŠŸ: @{author} ({post_id})")
                    return True
                else:
                    print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãµã‚ã‚‚ã“ç”»åƒã§ãªã„: {post_id} (ç”»åƒ {i+1})")
                    logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãµã‚ã‚‚ã“ç”»åƒã§ãªã„: {post_id} (ç”»åƒ {i+1})")
                    save_fuwamoko_uri(uri, indexed_at)
                    return False
            except Exception as e:
                print(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri}, cid={actual_post.cid})")
                logging.error(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri}, cid={actual_post.cid})")
                save_fuwamoko_uri(uri, indexed_at)
                return False
    except Exception as e:
        print(f"âŒ æŠ•ç¨¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri})")
        logging.error(f"âŒ æŠ•ç¨¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri})")
        save_fuwamoko_uri(uri, indexed_at)
        return False

def run_once():
    try:
        client = Client()
        session_str = load_session_string()
        if session_str:
            client.login(session_string=session_str)
            print(f"ğŸš€âœ¨ START: ãµã‚ã‚‚ã“Botèµ·å‹•ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨ï¼‰")
            logging.info("ğŸŸ¢ Botèµ·å‹•: ã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨")
        else:
            client.login(HANDLE, APP_PASSWORD)
            session_str = client.export_session_string()
            save_session_string(session_str)
            print(f"ğŸš€âœ¨ START: ãµã‚ã‚‚ã“Botèµ·å‹•ï¼ˆæ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰")
            logging.info("ğŸŸ¢ Botèµ·å‹•: æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³")

        print(f"ğŸ¦Š INFO: Botç¨¼åƒä¸­: {HANDLE}")
        logging.info(f"ğŸŸ¢ Botç¨¼åƒä¸­: {HANDLE}")
        load_fuwamoko_uris()
        reposted_uris = load_reposted_uris()

        timeline = client.get_timeline(limit=50)
        feed = timeline.feed
        for post in sorted(feed, key=lambda x: x.post.indexed_at, reverse=True):
            try:
                thread_response = client.get_post_thread(uri=str(post.post.uri), depth=2)
                process_post(thread_response.thread, client, fuwamoko_uris, reposted_uris)
            except Exception as e:
                print(f"âŒ ã‚¹ãƒ¬ãƒƒãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (URI: {post.post.uri})")
                logging.error(f"âŒ ã‚¹ãƒ¬ãƒƒãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (URI: {post.post.uri})")
            time.sleep(1.0)
    except Exception as e:
        print(f"âŒ Botå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        logging.error(f"âŒ Botå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

if __name__ == "__main__":
    try:
        load_dotenv()
        run_once()
    except Exception as e:
        logging.error(f"âŒ Botèµ·å‹•ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")