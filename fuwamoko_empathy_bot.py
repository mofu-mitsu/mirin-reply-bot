# ğŸ”½ ğŸ“¦ Pythonã®æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from datetime import datetime, timezone
import os
import time
import random
import requests
from io import BytesIO
import filelock
import re
import logging
import cv2
import numpy as np
from urllib.parse import quote, unquote
from PIL import Image, UnidentifiedImageError, ImageFile
from copy import deepcopy
import json

# ğŸ”½ ğŸŒ± å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer
from collections import Counter
import torch

# ğŸ”½ ğŸ“¡ atprotoé–¢é€£
from atproto import Client, models

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(filename='debug.log', level=logging.DEBUG, format='%(asctime)s %(message)s', encoding='utf-8')
logging.getLogger().addHandler(logging.StreamHandler())

# PILã®ã‚¨ãƒ©ãƒ¼æŠ‘åˆ¶
ImageFile.LOAD_TRUNCATED_IMAGES = True

# ğŸ”½ ğŸ§  Transformersç”¨è¨­å®š
MODEL_NAME = "cyberagent/open-calm-small"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=".cache")
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    cache_dir=".cache",
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto"
)
tokenizer.pad_token = tokenizer.eos_token

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
HANDLE = os.environ.get("HANDLE")
APP_PASSWORD = os.environ.get("APP_PASSWORD")
SESSION_FILE = "session_string.txt"
FUWAMOKO_FILE = "fuwamoko_empathy_uris.txt"
FUWAMOKO_LOCK = "fuwamoko_empathy_uris.lock"

# ğŸ”½ ãƒ†ãƒ³ãƒ—ãƒ¬å®šç¾©
LOCK_TEMPLATES = True
ORIGINAL_TEMPLATES = {
    "NORMAL_TEMPLATES_JP": [
        "ã†ã‚“ã†ã‚“ã€ã‹ã‚ã„ã„ã­ï¼ç™’ã•ã‚ŒãŸã‚ˆğŸ¾ğŸ’–",
        "ã‚ˆã‹ã£ãŸã­ã€œï¼ãµã‚ãµã‚ã ã­ğŸŒ¸ğŸ§¸",
        "ãˆã¸ã£ã€ãƒ¢ãƒ•ãƒ¢ãƒ•ã§ç™’ã—MAXï¼ğŸ’",
        "ã†ã‚ã£ï¼å¯æ„›ã™ãã‚‹ã‚ˆğŸ¾ğŸŒ·",
        "ãµã‚ãµã‚ã ã­ã€å…ƒæ°—å‡ºãŸï¼ğŸ’«ğŸ§¸"
    ],
    "SHONBORI_TEMPLATES_JP": [
        "ãã£ã‹â€¦ãã‚…ãƒ¼ã£ã¦ã—ã¦ã‚ã’ã‚‹ã­ğŸ¾ğŸ’•",
        "å…ƒæ°—å‡ºã—ã¦ã­ã€ãµã‚ã‚‚ã“ãƒ‘ãƒ¯ãƒ¼é€ã‚‹ã‚ˆï¼ğŸ§¸âœ¨",
        "ã¤ã‚‰ã„ã¨ãã“ãã€ãµã‚ãµã‚ã«åŒ…ã¾ã‚Œã¦â€¦ğŸ°â˜ï¸",
        "ç„¡ç†ã—ãªã„ã§ã­ã€ãã£ã¨å¯„ã‚Šæ·»ã†ã‚ˆğŸ§¸ğŸŒ¸"
    ],
    "MOGUMOGU_TEMPLATES_JP": [
        "ã†ãƒ¼ã‚“â€¦ã“ã‚Œã¯ç™’ã—ã‚ˆã‚Šç¾å‘³ã—ãã†ï¼ŸğŸ¾ğŸ’­",
        "ã‚‚ãã‚‚ãã—ã¦ã‚‹ã‘ã©â€¦ãµã‚ã‚‚ã“ã˜ã‚ƒãªã„ã‹ãªï¼ŸğŸ¤”",
        "ã¿ã‚Šã‚“ã¦ã‚ƒã´ã€ãŠè…¹ç©ºã„ãŸâ€¦é£Ÿãƒ¬ãƒï¼ŸğŸ½ï¸ğŸ’¬"
    ],
    "NORMAL_TEMPLATES_EN": [
        "Wow, so cute! Feels good~ ğŸ¾ğŸ’–",
        "Nice! So fluffy~ ğŸŒ¸ğŸ§¸",
        "Great! Healing vibes! ğŸ’",
        "Amazing! Thanks for the fluff! ğŸ¾ğŸ’–"
    ],
    "MOGUMOGU_TEMPLATES_EN": [
        "Hmmm... looks tasty, but maybe not so fluffy? ğŸ¾ğŸ’­",
        "So yummy-looking... but is this a snack or a friend? ğŸ¤”ğŸ½ï¸",
        "This might be food, not a fluffy cutie... ğŸ–",
        "Adorable! But maybe not a fluffy buddy? ğŸ‘ğŸ’–"
    ],
    "COSMETICS_TEMPLATES_JP": {
        "ãƒªãƒƒãƒ—": ["ã“ã®ãƒªãƒƒãƒ—å¯æ„›ã„ã€œğŸ’„ğŸ’–", "è‰²å‘³ãŒç´ æ•µã™ãã¦ã†ã£ã¨ã‚Šã—ã¡ã‚ƒã†ğŸ’‹"],
        "é¦™æ°´": ["ã“ã®é¦™ã‚Šã€çµ¶å¯¾ãµã‚ã‚‚ã“ã ã‚ˆã­ğŸŒ¸", "ã„ã„åŒ‚ã„ã€œï¼ğŸ’–ğŸ’•"],
        "ãƒã‚¤ãƒ«": ["ãã®ãƒã‚¤ãƒ«ã€ã‚­ãƒ©ã‚­ãƒ©ã—ã¦ã¦æœ€é«˜ğŸ’…âœ©âœ©", "ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼ã§ç´ æ•µã€œğŸ’–ğŸ’"]
    },
    "COSMETICS_TEMPLATES_EN": {
        "lip": ["That lipstick is so cute~ ğŸ’„ğŸ’–", "The color is dreamy, Iâ€™m in love ğŸ’‹ğŸ’–"],
        "perfume": ["I bet that perfume smells fluffy and sweet ğŸŒ¸ğŸ˜–", "I can almost smell it~ so lovely! ğŸ’–"],
        "nail": ["That nail art is sparkly and perfect ğŸ’…âœ©", "Fluffy colors make it so pretty ğŸ’–ğŸ’"]
    },
    "CHARACTER_TEMPLATES_JP": {
        "ã‚¢ãƒ‹ãƒ¡": ["ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ãŒãƒ¢ãƒ•ãƒ¢ãƒ•ï¼ğŸ’–", "ã¾ã‚‹ã§å¤¢ã®ä¸–ç•Œã®ä½äººâœ©âœ©"],
        "ä¸€æ¬¡å‰µä½œ": ["ã‚ªãƒªã‚­ãƒ£ãƒ©å°Šã„â€¦ğŸ¥ºâœ©", "ã“ã®å­ã ã‘ã®ä¸–ç•Œè¦³ğŸ’–"],
        "fanart": ["ã“ã®è§£é‡ˆã€å¤©æ‰ã™ãã‚‹â€¦ï¼ğŸ™Œ", "åŸä½œæ„›ãŒä¼ã‚ã£ã¦ãã‚‹ã‚ˆâœ©"]
    },
    "CHARACTER_TEMPLATES_EN": {
        "anime": ["Such a fluffy anime character! ğŸ’–ğŸ’–", "They look like someone from a dream world~ âœ©âœ©"],
        "oc": ["Your OC is precious... ğŸ¥ºâœ©", "They have such a unique vibe, I love it! ğŸ’–"],
        "fanart": ["Amazing interpretation! You're a genius ğŸ˜ŠğŸ™Œ", "I can feel your love for the original work âœ©âœ©"]
    }
}

# ğŸ”½ ã‚°ãƒ­ãƒ¼ãƒãƒ«è¾æ›¸åˆæœŸåŒ–
try:
    _ = globals()["HIGH_RISK_WORDS"]
except KeyError:
    logging.error("âš ï¸âš– HIGH_RISK_WORDSãŒæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["HIGH_RISK_WORDS"] = [
        "ã‚‚ã¡ã‚‚ã¡", "ã·ã«ã·ã«", "ã·ã‚ˆã·ã‚ˆ", "ã‚„ã‚ã‚‰ã‹ã„", "ã‚€ã«ã‚…ã‚€ã«ã‚…", "ã‚¨ãƒ­", "ãˆã£ã¡",
        "nude", "nsfw", "naked", "lewd", "18+", "sex", "uncensored"
    ]

try:
    _ = globals()["EMOTION_TAGS"]
except KeyError:
    logging.error("âš ï¸âš– EMOTION_TAGSãŒæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["EMOTION_TAGS"] = {
        "fuwamoko": ["ãµã‚ãµã‚", "ã‚‚ã“ã‚‚ã“", "ã‚‚ãµã‚‚ãµ", "fluffy", "fluff", "fluffball", "ãµã‚ã‚‚ã“",
                     "ã½ã‚ˆã½ã‚ˆ", "ã‚„ã‚ã‚„ã‚", "ãã‚…ã‚‹ãã‚…ã‚‹", "ã½ãµã½ãµ", "ãµã‚ã‚‚ãµ", "ã½ã“ã½ã“"],
        "neutral": ["ã‹ã‚ã„ã„", "cute", "adorable", "æ„›ã—ã„"],
        "shonbori": ["ã—ã‚‡ã‚“ã¼ã‚Š", "ã¤ã‚‰ã„", "ã‹ãªã—ã„", "ã•ã³ã—ã„", "ç–²ã‚ŒãŸ", "ã¸ã“ã‚“ã ", "æ³£ããã†"],
        "food": ["è‚‰", "ã”é£¯", "é£¯", "ãƒ©ãƒ³ãƒ", "ãƒ‡ã‚£ãƒŠãƒ¼", "ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°", "ã”ã¯ã‚“",
                 "ãŠã„ã—ã„", "ã†ã¾ã„", "ã„ãŸã ãã¾ã™", "ãŸã¹ãŸ", "ã”ã¡ãã†", "ã”é¦³èµ°",
                 "ã¾ãã‚", "åˆºèº«", "ãƒãƒ¼ã‚º", "ã‚¹ãƒŠãƒƒã‚¯", "yummy", "delicious", "ã‚¹ãƒ¼ãƒ—",
                 "å‘³å™Œæ±", "ã‚«ãƒ«ãƒœãƒŠãƒ¼ãƒ©", "é‹", "éºº", "ãƒ‘ãƒ³", "ãƒˆãƒ¼ã‚¹ãƒˆ",
                 "ã‚«ãƒ•ã‚§", "ã‚¸ãƒ¥ãƒ¼ã‚¹", "ãƒŸãƒ«ã‚¯", "ãƒ‰ãƒªãƒ³ã‚¯", "ãŠã‚„ã¤", "é£Ÿäº‹", "æœé£Ÿ", "å¤•é£Ÿ", "æ˜¼é£Ÿ",
                 "é…’", "ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«", "ãƒ“ãƒ¼ãƒ«", "ãƒ¯ã‚¤ãƒ³", "é…ãƒã‚¤", "ã‚«ã‚¯ãƒ†ãƒ«", "ãƒã‚¤ãƒœãƒ¼ãƒ«", "æ¢…é…’"],
        "safe_cosmetics": ["ã‚³ã‚¹ãƒ¡", "ãƒ¡ã‚¤ã‚¯", "ãƒªãƒƒãƒ—", "é¦™æ°´", "ã‚¹ã‚­ãƒ³ã‚±ã‚¢", "ãƒã‚¤ãƒ«", "çˆª", "ãƒãƒ‹ã‚­ãƒ¥ã‚¢",
                      "cosmetics", "makeup", "perfume", "nail", "lip", "lipstick", "lip gloss", "lip balm",
                      "fragrance", "scent", "nail art", "manicure", "nails"]
    }

try:
    _ = globals()['SAFE_CHARACTER']
except KeyError:
    logging.error("Error: âš ï¸ SAFE_CHARACTER is not defined. Injecting defaults.")
    globals()["SAFE_CHARACTER"] = {
        "ã‚¢ãƒ‹ãƒ¡": ["ã‚¢ãƒ‹ãƒ¡", "æ¼«ç”»", "ãƒãƒ³ã‚¬", "ã‚¤ãƒ©ã‚¹ãƒˆ", "anime", "illustration", "drawing", "anime art", "manga", "fanart"],
        "ä¸€æ¬¡å‰µä½œ": ["ä¸€æ¬¡åŸä½œ", "ã‚ªãƒªã‚­ãƒ£ãƒ©", "ã‚ªãƒªã‚¸ãƒŠãƒ«", "å‰µä½œ", "oc", "original character", "my oc"],
        "fanart": ["ãƒ•ã‚¡ãƒ³ã‚¢ãƒ¼ãƒˆ", "FA", "fanart", "fan art", "fandom art"]
    }

try:
    _ = globals()["GENERAL_TAGS"]
except KeyError:
    logging.error("Error: âš ï¸ GENERAL_TAGS is not defined. Injecting default.")
    globals()["GENERAL_TAGS"] = ["ã‚­ãƒ£ãƒ©", "æ¨ã—", "art", "drawing"]

# ãƒ†ãƒ³ãƒ—ãƒ¬ç›£æŸ»ãƒ­ã‚°
TEMPLATE_AUDIT_LOG = "template_audit_log.txt"

def audit_templates_changes(old, new):
    try:
        if old != new:
            with open(TEMPLATE_AUDIT_LOG, "a", encoding="utf-8") as f:
                f.write(json.dumps({
                    "timestamp": datetime.now().isoformat(),
                    "before": old,
                    "after": new
                }, ensure_ascii=False, indent=2) + "\n")
            logging.warning("Audit: âš ï¸ Template changes detected.")
    except Exception as e:
        logging.error(f"Error: Template audit failed: {type(e).__name__}: {e}")

def check_template_integrity(templates):
    if not LOCK_TEMPLATES:
        logging.warning("Warning: LOCK_TEMPLATES disabled, template modification risk detected.")
        return False
    for key in ORIGINAL_TEMPLATES:
        if templates.get(key) != ORIGINAL_T[key]:
            logging.error(f"Error: Template integrity violation for {key}, restoration recommended.")
            return False
    return True

def auto_revert_templates(templates):
    if LOCK_TEMPLATES:
        for key in ORIGINAL_TEMPLATES:
            templates[key] = deepcopy(ORIGINAL_TEMPLATES[key])
        logging.info("Templates: Templates successfully restored.")
        return templates
    return templates

def is_fluffy_color(r, g, b):
    logging.debug(f"Color check: RGB=({r}, {g}, {b})")
    if r > 230 and g > 230 and b > 230:  # White-like
        logging.debug("White-like color detected")
        return True
    if r > 210 and g < 100 and b > 180:  # Pink-like
        logging.debug("Pink-like color detected")
        return True
    if r > 240 and g > 230 and b > 180:  # Cream-like
        logging.debug("Cream-like color detected")
        return True
    if r > 220 and b > 220 and abs(r - b) < 30 and g > 200:  # Pastel purple
        logging.debug("Pastel purple detected")
        return True
    hsv = cv2.cvtColor(np.array([[[r, g, b]]], dtype=np.uint8), cv2.COLOR_RGB2HSV)[0][0]
    h, s, v = hsv
    logging.debug(f"HSV=({h}, {s}, {v})")
    if 200 <= h <= 300 and s < 50 and v > 200:  # Pastel (purple-pink)
        logging.debug("Pastel hue detected")
        return True
    if 100 <= h <= 250 and s < 100 and v > 150:  # Night sky pastel purple
        logging.debug("Night sky pastel purple detected")
        return True
    return False

def open_calm_reply(image_url, text="", context="ãµã‚ã‚‚ã“å…±æ„Ÿ", lang="ja"):
    NG_WORDS = globals()["EMOTION_TAGS"].get("nsfw_ng", [
        "åŠ å·¥è‚‰", "ãƒãƒ ", "ã‚½ãƒ¼ã‚»ãƒ¼ã‚¸", "ãƒ™ãƒ¼ã‚³ãƒ³", "ã‚µãƒ¼ãƒ¢ãƒ³", "ãŸã‚‰ã“", "æ˜å¤ªå­",
        "ãƒ‘ã‚¹ã‚¿", "ãƒ©ãƒ¼ãƒ¡ãƒ³", "å¯¿å¸", "ã†ã©ã‚“", "sushi", "sashimi", "salmon",
        "meat", "bacon", "ham", "sausage", "pasta", "noodle",
        "soft core", "NSFW", "è‚Œè‰²", "ä¸‹ç€", "è‚Œè¦‹ã›", "éœ²å‡º",
        "è‚Œãƒ•ã‚§ãƒ", "soft skin", "fetish"
    ])
    NG_PHRASES = [
        r"(?:æŠ•ç¨¿|ãƒ¦ãƒ¼ã‚¶ãƒ¼|ä¾‹æ–‡|æ“¬éŸ³èª|ãƒã‚¹ã‚¯ãƒƒãƒˆ|ãƒã‚¹ã‚±ãƒƒãƒˆ|ãƒ•ã‚©ãƒ¼ãƒ©ãƒ |è¿”äº‹|ä¼šè©±|å…±æ„Ÿ)",
        r"(?:ç™’ã—ç³»ã®ãµã‚ã‚‚ã“|æŠ•ç¨¿å†…å®¹ã«å¯¾ã—ã¦)",
        r"[â– #]{2,}",
        r"!{5,}", r"\?{5,}", r"[!ï¼Ÿ]{5,}",
        r"(?:(ãµã‚|ã‚‚ã“|ã‚‚ã¡|ã½ã“)\1{2,})",  # No triple+ word repetition
        r"[â™ª~]{2,}",  # No symbol chains
        r"#\S+#\S+",  # No hashtag chains
    ]

    templates = deepcopy(ORIGINAL_TEMPLATES)
    if not check_template_integrity(templates):
        templates = auto_revert_templates(templates)
    audit_templates_changes(ORIGINAL_TEMPLATES, templates)

    NORMAL_TEMPLATES_JP = templates["NORMAL_TEMPLATES_JP"]
    SHONBORI_TEMPLATES_JP = templates["SHONBORI_TEMPLATES_JP"]
    MOGUMOGU_TEMPLATES_JP = templates["MOGUMOGU_TEMPLATES_JP"]
    NORMAL_TEMPLATES_EN = templates["NORMAL_TEMPLATES_EN"]
    MOGUMOGU_TEMPLATES_EN = templates["MOGUMOGU_TEMPLATES_EN"]
    COSMETICS_TEMPLATES_JP = templates["COSMETICS_TEMPLATES_JP"]
    COSMETICS_TEMPLATES_EN = templates["COSMETICS_TEMPLATES_EN"]
    CHARACTER_TEMPLATES_JP = templates["CHARACTER_TEMPLATES_JP"]
    CHARACTER_TEMPLATES_EN = templates["CHARACTER_TEMPLATES_EN"]

    detected_tags = []
    for tag, words in globals()["EMOTION_TAGS"].items():
        if any(word in text.lower() for word in words):
            detected_tags.append(tag)

    if "food" in detected_tags or any(word.lower() in text.lower() for word in NG_WORDS):
        logging.debug(f"NG Food/NSFW detected: {text[:40]}...")
        return random.choice(MOGUMOGU_TEMPLATES_JP) if lang == "ja" else random.choice(MOGUMOGU_TEMPLATES_EN)
    elif "shonbori" in detected_tags:
        return random.choice(SHONBORI_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)
    elif "safe_cosmetics" in detected_tags:
        if lang == "ja":
            for cosmetic, templates in COSMETICS_TEMPLATES_JP.items():
                if cosmetic in text.lower():
                    return random.choice(templates)
        else:
            for cosmetic, templates in COSMETICS_TEMPLATES_EN.items():
                if any(word in text.lower() for word in globals()["EMOTION_TAGS"]["safe_cosmetics"]):
                    return random.choice(templates)
    elif any(tag in detected_tags for tag in globals()["SAFE_CHARACTER"]):
        if lang == "ja":
            for char_type, templates in CHARACTER_TEMPLATES_JP.items():
                if any(word in text.lower() for word in globals()["SAFE_CHARACTER"][char_type]):
                    return random.choice(templates)
        else:
            for char_type, templates in CHARACTER_TEMPLATES_EN.items():
                if any(word in text.lower() for word in globals()["SAFE_CHARACTER"][char_type]):
                    return random.choice(templates)
    elif any(word in text.lower() for word in globals()["GENERAL_TAGS"]):
        return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

    if not text.strip():
        text = "ãµã‚ãµã‚ãªå‹•ç‰©ã®ç”»åƒã ã‚ˆã€œğŸŒ¸"

    prompt = (
        f"ã‚ãªãŸã¯ç™’ã—ç³»ã§å¯æ„›ã„ãƒã‚¹ã‚³ãƒƒãƒˆã§ã™ã€‚\n"
        f"ä»¥ä¸‹ã®æŠ•ç¨¿ã‚’èª­ã‚“ã§ã€20ã€œ30æ–‡å­—ä»¥å†…ã®ãµã‚“ã‚ã‚Šå„ªã—ã„è¿”ä¿¡ã‚’1ã¤ä½œã£ã¦ãã ã•ã„ã€‚\n"
        f"çµµæ–‡å­—ã¯2ã€œ3å€‹ã€èªå°¾ã¯ã€Œã€œã­ï¼ã€ã€Œã€œã ã‚ˆï¼ã€ãªã©è¦ªã—ã¿ã‚„ã™ãã—ã¦ãã ã•ã„ã€‚\n"
        f"ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã€è¨˜å·ã®é€£ç¶šï¼ˆâ™ªã€œï¼‰ã€å˜èªã®éå‰°ãªç¹°ã‚Šè¿”ã—ï¼ˆãµã‚ãµã‚ãµã‚ï¼‰ã¯ç¦æ­¢ã§ã™ã€‚\n"
        f"è‡ªç„¶ã§å¯æ„›ã„é›°å›²æ°—ã«ã—ã¦ãã ã•ã„ã€‚\n"
        f"ä¾‹:\n"
        f"- ã‚ãã€œã‚‚ãµã‚‚ãµã®å­ã«ä¼šãˆãŸã®ï¼ŸğŸ’–ğŸ’–ğŸ’•\n"
        f"- ä»Šæ—¥ã‚‚ãµã‚ç™’ã•ã‚Œã‚‹ã­ï¼ğŸŒŸâœ©âœ©\n"
        f"- ãµã‚ã‚‚ã“ã§ç™’ã•ã‚Œã‚‹ã€œâ™¡ğŸ’–ğŸ’–\n"
        f"- ãã‚“ãªè¡¨æƒ…ã€ã‹ã‚ã„ã™ãã‚‹ã‚ˆã€œğŸ–ğŸŒ¸ğŸ’•\n"
        f"æŠ•ç¨¿: {text.strip()[:100]}\n"
        f"è¿”ä¿¡: ###\n"
    )
    logging.debug(f"ğŸ§ª ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç¢ºèª: {prompt}")

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=150).to(model.device)
    try:
        outputs = model.generate(
            **inputs,
            max_new_tokens=40,
            pad_token_id=tokenizer.pad_token_id,
            do_sample=True,
            temperature=0.7,
            top_k=50,
            top_p=0.9,
            no_repeat_ngram_size=3,
            stopping_criteria=[lambda ids, scores: "###" in tokenizer.decode(ids[0], skip_special_tokens=True)]
        )
        raw_reply = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
        logging.debug(f"ğŸ§¸ Raw AIå‡ºåŠ›: {raw_reply}")

        reply = re.sub(r'^.*?###\s*', '', raw_reply, flags=re.DOTALL).strip()
        reply = re.sub(r'^.*?(?:ã‚ãªãŸã¯ç™’ã—ç³»ã®|æŠ•ç¨¿å†…å®¹ã«å¯¾ã™ã‚‹:).*?$', '', reply, flags=re.DOTALL).strip()

        if not reply or len(reply) < 5:
            logging.warning(f"â­ï¸ SKIP: ç©ºã¾ãŸã¯çŸ­ã™ã: len={len(reply)}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        if len(reply) < 15 or len(reply) > 35:
            logging.warning(f"â­ï¸ SKIP: é•·ã•ä¸é©åˆ‡: len={len(reply)}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        for bad in NG_PHRASES:
            if re.search(bad, reply.lower()):
                logging.warning(f"â­ï¸ SKIP: NGãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œå‡º: {bad}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}")
                return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        emoji_count = len(re.findall(r'[ğŸ˜ºğŸ¾ğŸ§¸ğŸŒ¸ğŸŒŸğŸ’•ğŸ’–âœ¨â˜ï¸ğŸŒ·ğŸ°]', reply))
        if emoji_count < 2 or emoji_count > 3:
            logging.warning(f"â­ï¸ SKIP: çµµæ–‡å­—æ•°ä¸é©åˆ‡: count={emoji_count}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        logging.info(f"ğŸ¦Š AIç”ŸæˆæˆåŠŸ: {reply}")
        return reply
    except Exception as e:
        logging.error(f"âŒ AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

def extract_valid_cid(ref):
    try:
        cid_candidate = str(ref.link) if hasattr(ref, 'link') else str(ref)
        if re.match(r'^baf[a-z0-9]{40,60}$', cid_candidate):
            return cid_candidate
        logging.error(f"Error: Invalid CID: {cid_candidate}")
        return None
    except Exception as e:
        logging.error(f"Error extracting CID: {type(e).__name__}: {e}")
        return None

def check_skin_ratio(img_pil_obj):
    try:
        if img_pil_obj is None:
            logging.debug("Debug: Invalid image data (PIL Image object is None)")
            return 0.0

        img_pil_obj = img_pil_obj.convert("RGB")
        img_np = cv.cvtColor(np.array(img_pil_obj), cv2.cvtColor_RGB2BGR)
        if img_np is None or img_np.size == 0:
            logging.error("Error: Invalid image data")
            return 0.0

        hsv_img = cv2.cvtColor(img_np, cv2.COLOR2HSV_BGR2HSV)
        lower = np.array([0, 20, 70], dtype=np.uint8)
        upper = np.array([20, 255], dtype=np.uint8)
        mask = cv2.inRange(hsv_img, lower, upper)
        skin_colors = img_np[mask > 0]
        if skin_colors.size > 0:
            avg_color = np.mean(skin_colors, axis=0)
            logging.debug(f"Average: skin color: BGR={avg_color}")
        skin_area = np.sum(mask > 0)
        total_area = img_np.shape[0] * img_np.shape[1]
        skin_ratio = skin_area / total_area if total_area > 0 else 0.0
        logging.debug(f"Skin ratio: {skin_ratio:.2f}%")
        return skin_ratio
    except Exception as e:
        logging.error(f"Error: Skin ratio analysis error: {type(e).__name__}: {e}")
        return 0.0

def is_mutual_follow(client, handle):
    try:
        their_followers = client.get_followers(actor=actor_followers).followers
        their_followers = {f.handle for f in their_followers}
        my_followers = client.get_followers(actor=HANDLE).followers
        my_followers = {f.handle for f in my_followers}
        return handle in my_followers and HANDLE in their_followers
    except Exception as e:
        logging.error(f"Error: Mutual follow check failed: {type(e).__name__}: {e}")
        return False

def download_image_from_blob(cid, client, did=None):
    if not cid or not re.match(r'^baf[a-z0-9}{40,60}$', cid):
        logging.error(f"Error: Invalid: {cid}")
        return None

    if client and did:
        try:
            logging.debug(f"Debug: Blob API request started: for CID={cid}, DID={did}")
            blob = client.com.atproto.get_blob.get_blob(cid=cid, did=did))
            logging.debug(f"Blob API success: size={len(blob.data)} bytes")
            img_data = BytesIO(blob.data)
            try:
                img = Image.open(img_data)
                logging.info(f"Success: {img.format}, Image format= JPEG, size={img.size}")
                img.load()
                return img
            except (UnidentifiedImageError, OSError) as e:
                logging.error(f"Error: Blob image parse failed: {type(e).__name__}: {e}")
                return None
            except Exception as e:
                logging.error(f"Error: Blob image load error: {type(e).__name__} {e}")
                return None
        except Exception as e:
            logging.error(f"Error: {error} Blob API error: {type(e).__name__}: {e}")

    did_safe = unquote(did) if did else None
    cdn_urls = [
        f"https://cdn.bsky.app/cdn.bsky.app/feed_thumbnail/plain/{quote(did_safe)}/{quote(cid)}/{cid}@jpeg" if did_safe else None,
        f"https://cdn.bsky.app/feed_fullsize/{plain(quote(cid_safe))}@{quote(cid)}/{cid}@jpeg" if did_safe else None
    ]
    headers = {"User-Agent": "Mozilla/5.0"}

    for url in [u for u in cdn_urls if u]:
        try:
            logging.debug(f"Debug: {f"CDN request started: for CID={cid}, url={url}")
            response = requests.get(url, headers=headers, timeout=10, stream=True)
            response.raise_for_status()
            logging.debug(f"CDN fetch success: size={len(response.content)} bytes")
            img_data = BytesIO(response.content)
            try:
                img = Image.open(img_data)
                logging.info(f"Success: Image format={img.format}, size={img.size}")
                img.load()
                return img
            except (UnidentifiedImageError, OSError) as e:
                logging.error(f"Error: Image parse failed: {type(e).__name__}: {e}, url={url}")
                return None
            except Exception as e:
                logging.error(f"Error: {error}fetch failed: {type(e).__name__}: {e}, url={url}")
                return None
        except requests.RequestException as e:
            logging.error(f"Error: CDN request failed: {type(e)}.__name__}: {e}, url={url}")
            continue

    logging.error(f"Error: Image fetching failed}")
    return None

def process_image(image_data, text="", client=None, post=None):
    if not hasattr(image_data, 'image') or not hasattr(image_data.image, 'ref'):
        logging.debug("Debug: Abnormal image data structure")
        return False

    cid = extract_valid_id(ref)
    if not cid:
        return False

    try:
        author_did = post.author.did if post and hasattr(post, 'post') else None
        img = download_image_from_blob(cid, client, did=author_did)
        if img is None:
            logging.warning(f"âš ï¸ Skip: Skipped: Image fetch failed (log above)")
            return False

        resized_img = img.resize((64, 64))
        colors = resized_img.getdata()
        color_counts = Counter(colors)
        top_colors = color_counts.most_common(5)
        logging.debug(f"Top 5 colors: {[(c[0][:3], c[1]) for c in top_colors]}")

        fluffy_count = 0
        for color in top_colors:
            r, g, b = color[0][:3]
            if is_fluffy_color(r, g, b):
                fluffy_count += 1
        logging.debug(f"Fluffy color count: {fluffy_count}")

        skin_ratio = check_skin_ratio(img)
        if skin_ratio > 0.4:
            logging.warning(f"Skipped: High skin ratio: {skin_ratio:.2%}")
            return False

        check_text = text.lower()
        try:
            if any(word in check_text for word in globals()["HIGH_RISK_WORDS"]):
                if skin_ratio < 0.4 and fluffy_count >= 2:
                    logging.info("Success: High risk but conditions met")
                    return True
                else:
                    logging.warning("Skipped: High risk and conditions not met")
                    return False
        except KeyError:
            logging.error("Error: HIGH_RISK_WORDS undefined. Skipping.")
            return False

        if fluffy_count >= 2:
            logging.info("Success: Fluffy colors detected")
            return True
        else:
            logging.warning("Skipped: Insufficient fluffy colors")
            return False
    except Exception as e:
        logging.error(f"Error: Image processing error: {type(e).__name__}: {e}")
        return False

def is_quoted_repost(post):
    try:
        actual_post = post.post if hasattr(post, 'post') else post
        record = getattr(actual_post, 'record', None)
        if record and hasattr(record, 'embed') and record.embed:
            embed = record.embed
            logging.debug(f"Quote repost check: {embed}")
            if hasattr(embed, 'record') and embed.record:
                logging.debug("Quote repost detected (record)")
                return True
            elif hasattr(embed, 'record') and hasattr(embed.record, 'record') and embed.record.record:
                logging.debug("Quote repost detected (recordWithMedia)")
                return True
        return False
    except Exception as e:
        logging.error(f"Error: Quote repost check failed: {type(e).__name__}: {e}")
        return False

def load_reposted_uris():
    REPOSTED_FILE = "reposted_uris.txt"
    if os.path.exists(REPOSTED_FILE):
        try:
            with open(REPOSTED_FILE, 'r', encoding='utf-8') as f:
                uris = set(line.strip() for line in f if line.strip())
                logging.info(f"Success: Loaded {len(uris)} reposted URIs")
                return uris
        except Exception as e:
            logging.error(f"Error: Failed to load reposted URIs: {type(e).__name__}: {e}")
            return set()
    return set()

def detect_language(client, handle):
    try:
        profile = client.get_profile(actor=handle)
        bio = profile.display_name.lower() + " " + getattr(profile, "description", "").lower()
        if any(kw in bio for kw in ["æ—¥æœ¬èª", "æ—¥æœ¬", "ã«ã»ã‚“", "japanese", "jp"]):
            return "ja"
        elif any(kw in bio for kw in ["english", "us", "uk", "en"]):
            return "en"
        return "ja"
    except Exception as e:
        logging.error(f"Error: Language detection failed: {type(e).__name__}: {e}")
        return "ja"

def is_priority_post(text):
    return "@mirinchuuu" in text.lower()

def is_reply_to_self(post):
    reply = getattr(post.record, "reply", None) if hasattr(post, 'record') else None
    if reply and hasattr(reply, 'parent') and hasattr(reply.parent, 'uri'):
        return reply.parent.uri == post.post.uri
    return False

fuwamoko_uris = {}

def normalize_uri(uri):
    try:
        if not uri.startswith('at://'):
            uri = f"at://{uri.lstrip('/')}"
        parts = uri.split('/')
        if len(parts) >= 5:
            normalized = f"at://{parts[2]}/{parts[3]}/{parts[4]}"
            logging.debug(f"Normalized URI: {uri} -> {normalized}")
            return normalized
        logging.warning(f"Failed to normalize URI: Invalid format: {uri}")
        return uri
    except Exception as e:
        logging.error(f"Error normalizing URI: {type(e).__name__}: {e}")
        return uri

def validate_fuwamoko_file():
    if not os.path.exists(FUWAMOKO_FILE):
        logging.info("Info: Fuwamoko history file does not exist. Creating new.")
        with open(FUWAMOKO_FILE, 'w', encoding='utf-8') as f:
            f.write("")
        return True
    try:
        with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for line in lines:
                clean_line = line.strip()
                if not clean_line:
                    continue
                if not re.match(r'^at://[^|]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}(?:\d{3})?\+\d{2}:\d{2}$', clean_line):
                    logging.error(f"Invalid history line: {repr(clean_line)}")
                    return False
        return True
    except Exception as e:
        logging.error(f"Error validating history file: {type(e).__name__}: {e}")
        return False

def repair_fuwamoko_file():
    temp_file = FUWAMOKO_FILE + ".tmp"
    valid_lines = []
    if os.path.exists(FUWAMOKO_FILE):
        try:
            with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    clean_line = line.strip()
                    if not clean_line:
                        continue
                    if re.match(r'^at://[^|]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}(?:\d{3})?\+\d{2}:\d{2}$', clean_line):
                        valid_lines.append(line)
                    else:
                        logging.warning(f"Skipped corrupted line: {repr(clean_line)}")
            with open(temp_file, 'w', encoding='utf-8') as f:
                f.writelines(valid_lines)
            os.replace(temp_file, FUWAMOKO_FILE)
            logging.info(f"Success: History file repaired, retained {len(valid_lines)} entries")
        except Exception as e:
            logging.error(f"Error repairing history file: {type(e).__name__}: {e}")
            if os.path.exists(temp_file):
                os.remove(temp_file)
    else:
        with open(FUWAMOKO_FILE, 'w', encoding='utf-8') as f:
            f.write("")
        logging.info("Success: Created new history file")

def load_fuwamoko_uris():
    global fuwamoko_uris
    fuwamoko_uris.clear()
    if not validate_fuwamoko_file():
        logging.warning("Warning: History file corrupted. Attempting repair.")
        repair_fuwamoko_file()
    try:
        with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
            logging.info(f"Success: Fuwamoko history size: {len(content)} bytes")
            if content.strip():
                for line in content.splitlines():
                    if line.strip():
                        try:
                            uri, timestamp = line.strip().split("|", 1)
                            normalized_uri = normalize_uri(uri)
                            fuwamoko_uris[normalized_uri] = datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
                            logging.debug(f"Loaded history: {normalized_uri}")
                        except ValueError as e:
                            logging.warning(f"Skipped corrupted line: {repr(line.strip())}: {e}")
                            continue
            logging.info(f"Success: Loaded {len(fuwamoko_uris)} fuwamoko URIs")
    except Exception as e:
        logging.error(f"Error: Failed to load fuwamoko URIs: {type(e).__name__}: {e}")
        fuwamoko_uris.clear()

def save_fuwamoko_uri(uri, indexed_at):
    global fuwamoko_uris
    normalized_uri = normalize_uri(uri))
    lock = filelock.FileLock(FUWAMOKO_LOCK, timeout=5.0)
    try:
        with lock:
            logging.debug(f"Debug: Lock acquired: {FUWAMOKO_LOCK}")
            if normalized_uri in fuwamoko_uris and (datetime.now(timezone.utc) - fuwamoko_uris[normalized_uri]).total_seconds() < 24 * 3600:
                logging.debug(f"Skipped: Within 24 hours: {normalized_uri}")
                return
            if isinstance(indexed_at, str)):
                indexed_at = datetime.fromisoformat(indexed_at.replace("Z", str)+00:00"))
            with open(FUWAMOKO_FILE, flags='a', encoding='utf-8') as f:
                f.write(f"{normalized_uri}|{lineindexed_at.isoformat()}}\n")
            fuwamoko_uris[normalized_uri] = indexed_at  # Memory update
            logging.info(f"Success: Saved history: {normalized_uri: {normalized_uri}")
            # Verify file
            with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                last_line = lines[-1].strip() if lines else ""
                if last_line.startswith(normalized_uri):
                    logging.debug(f"Verified file: Last line: {last_line}")
                else:
                    logging.error(f"Error: History save failed: Last line: {last_line}")
            load_fuwamoko_uris()  # Reload after save
    except filelock.Timeout:
        logging.error(f"Error: File lock timeout: {FUWAMOKO}: {lock}")
    except Exception as e:
        logging.error(f"Error: History save error: {type(e).__name__}: {e}")

def load_session_string():
    try:
        if os.path.exists(SESSION_FILE):
            with open(SESSION_FILE, 'r', encoding='utf-8') as f:
                return f.read().strip()
        return None
    except Exception as e:
        logging.error(f"Error: Session load error: {type(e)__name__}: {e}")
        return None

def save_session_string(session_str):
    try:
        with open(SESSION_FILE, 'w', encoding='utf-8') as f:
            f.write(session_str)
    except Exception as e:
        logging.error(f"Error: Session save error: {type(e)__name__}: {e}")

def has_image(post_data):
    try:
        actual_post = post_data.post if hasattr(post_data, 'post') else post_data
        if not hasattr(actual_post, 'record') or not hasattr(actual_post.record, 'embed'):
            return False
        embed = actual_post.record.embed
        return (
            (hasattr(embed, 'images') and embed.images) or
            (
                hasattr(embed, 'record') and hasattr(embed.record, 'embed') and 
                hasattr(embed.record.embed, 'images') and embed.record.embed.images
            ) or
            (
                getattr(embed, '$type', '') == 'app.bsky.embed.recordWithMedia' and 
                hasattr(embed, 'media') and hasattr(embed.media, 'images') and embed.media.images
            )
        )
    except Exception as e:
        logging.error(f"Error: Image check error: {type(e)__name__}: {e}")
        return False

def process_post(post_data, client, fuwammoko_uris, reposted_uris):
    try:
        actual_post = post_data.post if hasattr(post_data, 'post') else post_data
        uri = str(actual_post.uri)
        post_id = uri.split('/')[-1]
        text = getattr(actual_post.record, 'text', '') if hasattr(actual_post.record, 'text') else ''

        is_reply = hasattr(actual_post.record, 'reply') and actual_post.record.reply is not None
        if is_reply and not (is_priority_post(text) or is_reply_to_self(post_data)):
            print(f"â­ Skipped: Reply post (non-priority/non-self): {text[:20]} ({post_id})")
            logging.debug(f"Skipped: Reply post: {post_id}")
            return False

        print(f"ğŸ¦Š Processing post: @{actual_post.author.handle} ({post_id})")
        logging.info(f"Success: Processing post: @{actual_post.author.handle} ({post_id})")
        normalized_uri = normalize_uri(uri)
        if normalized_uri in fuwammoko_uris:
            print(f"â­ Skipped: Existing post: {post_id}")
            logging.debug(f"Skipped: Existing post: {post_id}")
            return False
        if actual_post.author.handle == HANDLE:
            print(f"â­ Skipped: Own post: {post_id}")
            logging.debug(f"Skipped: Own post: {post_id}")
            return False
        if is_quoted_repost(post_data):
            print(f"â­ Skipped: Quote repost: {post_id}")
            logging.debug(f"Skipped: Quote repost: {post_id}")
            return False
        if post_id in reposted_uris:
            print(f"â­ Skipped: Already reposted: {post_id}")
            logging.debug(f"Skipped: Already reposted: {post_id}")
            return False

        author = actual_post.author.handle
        indexed_at = actual_post.indexed_at

        if not has_image(post_data):
            print(f"â­ Skipped: No images: {post_id}")
            logging.debug(f"Skipped: No images: {post_id}")
            return False

        image_data_list = []
        embed = getattr(actual_post.record, 'embed', None)
        if embed:
            if hasattr(embed, 'images') and embed.images:
                image_data_list.extend(embed.images)
            elif hasattr(embed, 'record') and hasattr(embed.record, 'embed') and hasattr(embed.record.embed, 'images'):
                image_data_list.extend(embed.record.embed.images)
            elif getattr(embed, '$type', '') == 'app.bsky.embed.recordWithMedia' and hasattr(embed, 'media') and hasattr(embed.media, 'images'):
                image_data_list.extend(embed.media.images)

        if not is_mutual_follow(client, author):
            print(f"â­ Skipped: Non-mutual follow: @{author} ({post_id})")
            logging.debug(f"Skipped: Non-mutual follow: @{author} ({post_id})")
            return False

        for i, image_data in enumerate(image_data_list):
            try:
                print(f"ğŸ¦Š Processing image: {i+1}/{len(image_data_list)} ({post_id})")
                logging.debug(f"Processing image: {i+1}/{len(image_data_list)} ({post_id})")
                if process_image(image_data, text, client=client, post=post_data):
                    if random.random() > 0.5:
                        print(f"â­ Skipped: Random (50%): {post_id}")
                        logging.debug(f"Skipped: Random: {post_id}")
                        save_fuwamoko_uri(uri, indexed_at)
                        return False
                    lang = detect_language(client, author)
                    reply_text = open_calm_reply("", text, lang=lang)
                    if not reply_text:
                        print(f"â­ Skipped: Reply generation failed: {post_id}")
                        logging.debug(f"Skipped: Reply generation failed: {post_id}")
                        save_fuwamoko_uri(uri, indexed_at)
                        return False
                    root_ref = models.ComAtprotoRepoStrongRef.Main(
                        uri=uri,
                        cid=actual_post.cid
                    )
                    parent_ref = models.ComAtprotoRepoStrongRef.Main(
                        uri=uri,
                        cid=actual_post.cid
                    )
                    reply_ref = models.AppBskyFeedPost.ReplyRef(
                        root=root_ref,
                        parent=parent_ref
                    )
                    print(f"ğŸ¦Š Sending reply: @{author}: {reply_text} ({post_id})")
                    logging.debug(f"Sending reply: @{author}: {reply_text} ({post_id})")
                    client.send_post(text=reply_text, reply_to=reply_ref)
                    save_fuwamoko_uri(uri, indexed_at)
                    print(f"âœ… SUCCESS: Reply sent: @{author} ({post_id})")
                    logging.info(f"Success: Reply sent: @{author} ({post_id})")
                    return True
                else:
                    print(f"â­ Skipped: Non-fuwamoko image: {post_id} (image {i+1})")
                    logging.warning(f"Skipped: Non-fuwamoko image: {post_id} (image {i+1})")
                    save_fuwamoko_uri(uri, indexed_at)
                    return False
            except Exception as e:
                print(f"âŒ Image processing error: {type(e).__name__}: {e} ({post_id}, uri={uri}, cid={actual_post.cid})")
                logging.error(f"Error: Image processing error: {type(e).__name__}: {e} ({post_id}, uri={uri}, cid={actual_post.cid})")
                save_fuwamoko_uri(uri, indexed_at)
                return False
    except Exception as e:
        print(f"âŒ Post processing error: {type(e).__name__}: {e} ({post_id}, uri={uri})")
        logging.error(f"Error: Post processing error: {type(e).__name__}: {e} ({post_id}, uri={uri})")
        save_fuwamoko_uri(uri, indexed_at)
        return False

def run_once():
    try:
        client = Client()
        session_str = load_session_string()
        if session_str:
            client.login(session_string=session_str)
            print(f"ğŸš€âœ¨ START: FuwamokoBot launched (reused session)")
            logging.info("Success: Bot launched with reused session")
        else:
            client.login(HANDLE, APP_PASSWORD)
            session_str = client.export_session_string()
            save_session_string(session_str)
            print(f"ğŸš€âœ¨ START: FuwamokoBot launched (new session)")
            logging.info("Success: Bot launched with new session")

        print(f"ğŸ¦Š INFO: Bot running: {HANDLE}")
        logging.info(f"Success: Bot running: {HANDLE}")
        load_fuwamoko_uris()
        reposted_uris = load_reposted_uris()

        timeline = client.get_timeline(limit=50)
        feed = timeline.feed
        for post in sorted(feed, key=lambda x: x.post.indexed_at, reverse=True):
            try:
                thread_response = client.get_post_thread(uri=str(post.post.uri), depth=2)
                process_post(thread_response.thread, client, fuwamoko_uris, reposted_uris)
            except Exception as e:
                print(f"âŒ Thread fetch error: {type(e).__name__}: {e} (URI: {post.post.uri})")
                logging.error(f"Error: Thread fetch error: {type(e).__name__}: {e} (URI: {post.post.uri})")
            time.sleep(1.0)
    except Exception as e:
        print(f"âŒ Bot execution error: {type(e).__name__}: {e}")
        logging.error(f"Error: Bot execution error: {type(e).__name__}: {e}")

if __name__ == "__main__":
    try:
        load_dotenv()
        run_once()
    except Exception as e:
        logging.error(f"Error: Bot startup error: {type(e).__name__}: {e}")